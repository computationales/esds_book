---
title: "Application 01 - Solution"
output: html_document
---

# Variable Selection

First we generate our data.

```{r}
set.seed(41)

#data size
n = 500

#predictors
x1 = rnorm(n)
x2 = rnorm(n)
x3 = rnorm(n)

#generate output
y = 4*x1 + 3*x3 + rnorm(n)

df_data = data.frame(y = y, x1 = x1,x2 = x2, x3 = x3)
head(df_data)
```
The true underline model uses as predictors the variables x1 and x3. However in practise we do not know this information. What we really see is the df_data file. For this exercise we want to find those variables that are most informatives. Since we have 3 available predictors we can create 7 different models using all possible combinations of predictors. This type of variable selection is reffered as _Best Subset Selection_.

```{r}
formulas = c('y~x1','y~x2','y~x3','y~x1+x2','y~x1+x3','y~x2+x3','y~x1+x2+x3')
cat("All possible models \n",paste(formulas,collapse = ' , '),'\n')

```

In order to find the optimal model we will use two methods:
 
 a. BIC
 b. Cross Validated MSE

We note here that the BIC criterion uses all the available data while the MSE uses the cross validated test data.

## BIC
```{r}
#create vector that stores the BIC results for all the models
bic_s = rep(NA,length(formulas))

#iterate over the models
for (i in 1:length(formulas)){
  #construct formula
  formula = as.formula(formulas[i])
  
  #fit linear model
  lm_fit = lm(formula,data = df_data)
  
  #calculate bic
  bic_s[i] = BIC(lm_fit)
}

```

find the optimal model according to BIC
```{r}
#find the optimal model according to BIC
cat("Optimal Model BIC: ",formulas[which.min(bic_s)])
```

## Cross Validated MSE
```{r}
#shuffle the data
shuffled_id = sample(x = 1:n, size = n)
df_data = df_data[shuffled_id,]

#specify the number of folds
n_folds = 5

#folds assignments (in which folder each point is assigned)
folds = cut(1:n,breaks = n_folds,labels = FALSE)

#create matrix to store the MSE from each test folder for all models : dimension 7 x n_folds
mse_s = matrix(NA,nrow = length(formulas),ncol = n_folds)

#iterate over the models
for (i in 1:length(formulas)){
  #construct formula
  formula = as.formula(formulas[i])
  
  #cross validation for the i-th model
  for(j in 1:n_folds){
    #take train indixes for all folders except j
    train_ind = (folds != j)
    #take test indexes for folder j
    test_ind = (folds == j)
    
    #train data that contains all the points that do not belong in folder j
    train_data = df_data[train_ind,]
    #test data that contains all the points that belong to folder j
    test_data = df_data[test_ind,]
    
    #fit linear model using the training data
    lm_fit = lm(formula, data = train_data)
    
    # calculate mse on test data
    ## make predictions
    y_pred = predict(lm_fit,test_data)
    #calculate mse of test folder --> jth folder
    mse = mean((y_pred - test_data$y)^2)
    
    mse_s[i,j] = mse
  }
}  
```

Check the MSE error for each test folder for every model.
```{r}
mse_s
```

Calculate Cross Validated MSE for every model.
```{r}
cv_mse = rowMeans(mse_s)
cv_mse
```

Find the optimal model according to Cross Validated MSE.
```{r}
#find the optimal model according to CV 
cat("Optimal Model CV_MSE: ",formulas[which.min(cv_mse)])
```

