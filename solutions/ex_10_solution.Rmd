---
title: "Exercise 10 - Solution"
output: html_document
---

# Supervised Learning Neural Networks II
## Import libraries
```{r}
library(tidyverse)
library(reticulate)
use_condaenv()
library(keras)
library(rsample)
```

## Import functions
```{r}

#Area Under Curve
simple_auc <- function(x, y){
  #Revert order
  x = rev(x)
  y = rev(y)  
  #Define rectangles, calculate area and add those
  dx <- c(diff(x), 0)
  dy <- c(diff(y), 0)
  sum(y * dx) + sum(dy * dx)/2
}

#ROC CURVE
ROC = function(fpr, recall, viz = T){
     
    #Calculate the area under the ROC
    auc = simple_auc(fpr,recall)
     
    #Visualize the ROC
    if (viz){
        
        x = seq(0,1,length.out = 100)
        g = ggplot() +
        geom_line(aes(x = fpr, y = recall,color='Model') , lty =2,lwd = 1.2)+
        geom_line(aes(x=x,y=x,color = 'Baseline'),inherit.aes = F,lty=2,alpha=0.8)+
        labs(x = 'False Positive Rate',
             y = 'Recall',
             color='',
             title='Area Under The curve ROC',
            subtitle=paste("AUC : ",round(auc,2)))+
        theme_grey(base_size = 20)
    }
    else{
        g = NA
    }
    
    return (list(plot = g,value = auc))
}

confusion = function(y_true, pred_out, threshold = 0.5, verbose = T){
  
  true_positives = sum((pred_out >= threshold) & (y_true == 1))
  true_negatives = sum((pred_out < threshold) & (y_true == 0))
  false_positives = sum((pred_out >= threshold) & (y_true == 0))
  false_negatives = sum((pred_out < threshold) & (y_true == 1))
  
  if (verbose) {
    cat('true positives: ',true_positives,'\n')
    cat('true negatives: ',true_negatives,'\n')
    cat('false positives: ',false_positives,'\n')
    cat('false negatives: ',false_negatives,'\n')
  }
  return (list(tp = true_positives, tn = true_negatives, fp = false_positives, fn = false_negatives))
}

precision_and_recall = function(true_positives, true_negatives,false_positives, false_negatives, verbose=T){
  
  #Protect against division by zero
  if ((true_positives + false_positives) > 0){
    precision = true_positives /(true_positives + false_positives)
  }
  else{
    precision = 1
  }
  
  if ((true_positives + false_negatives) > 0){    
    recall = true_positives / (true_positives + false_negatives)
  }
  else{
      recall = 0
  }
  
  if (verbose){
    cat("Precision: " ,precision,"\n")
    cat("Recall: ",recall,"\n")
  }
  
  return (list(precision = precision, recall = recall))
}

f_score = function(precision,recall,verbose=T){
    
    #Calculate F
    f = 2*precision*recall/(precision+recall)
    
    #If the user has requested verbose output, provide it
    if(verbose){
        cat("F-score: ",f,"\n")
    }
    
    #Return F
    return(f)
}
```


## Read data
```{r}
df_data = read_csv('../data/ex10_data.csv')
head(df_data)
```

## Visualize data and print proportion of data belongs to each class
```{r}
#visualize the data
df_data %>% 
    ggplot(aes(x = x1 , y = x2, color = as.factor(y)))+
    geom_point()+
    scale_color_manual(name = 'Class',labels = c('0','1'),values = c('0'="green",'1'='blue'))+
    labs(linetype='')+
    theme_grey(base_size = 15)


#print some summary statistics about these data
cat('Proportion of data in class blue: ' , sum(df_data$y)/length(df_data$y),'\n')
cat('Proportion of data in class green: ' , 1-sum(df_data$y)/length(df_data$y),'\n')
```

## Split into training and test set (Stratified split)
```{r}
split <- initial_split(df_data, prop = 0.8, strata = 'y')
df_train <- training(split)
df_test <- testing(split)
```

## Create models
```{r}
models = list()
#Create models
num_epochs = 100
learning_rate = 0.01
batch_size = 512
# 1 hidden layer 5 units
model_1 = keras_model_sequential()
model_1 = model_1 %>% 
          layer_dense(units = 5, activation="relu") %>%
          layer_dense(units=1, activation="sigmoid") 
          
#Specify the learning rate for stochastic gradient descent
opt = optimizer_adam(lr = learning_rate)

#Compile the model, using binary cross-entropy to define loss. Measure accuracy during training.
model_1 %>% compile(optimizer=opt, loss='binary_crossentropy', metrics= list('accuracy'))         

#Fit the model
model_1 %>% fit(x = as.matrix(df_train[,c('x1','x2')]),
                y = df_train$y,
                epochs=num_epochs,
                batch_size=batch_size,
                )  

#add to list 
models[[1]] = model_1

# 2 hidden layer 1st 10 units and 2nd 5 units
model_2 = keras_model_sequential()
model_2 = model_2 %>% 
          layer_dense(units = 10, activation="relu") %>%
          layer_dense(units = 5, activation="relu") %>%
          layer_dense(units=1, activation="sigmoid") 
          
#Specify the learning rate for stochastic gradient descent
opt = optimizer_adam(lr = learning_rate)

#Compile the model, using binary cross-entropy to define loss. Measure accuracy during training.
model_2 %>% compile(optimizer=opt, loss='binary_crossentropy', metrics= list('accuracy'))         

#Fit the model
model_2 %>% fit(x = as.matrix(df_train[,c('x1','x2')]),
                y = df_train$y,
                epochs=num_epochs,
                batch_size=batch_size,
                )  

#add to list 
models[[2]] = model_2

# 4 hidden layer 1st 10 units, 2nd 10, 3nd 10 units and 4rd 5 units
model_3 = keras_model_sequential()
model_3 = model_3 %>% 
          layer_dense(units = 10, activation="relu") %>%
          layer_dense(units = 10, activation="relu") %>%
          layer_dense(units = 10, activation="relu") %>%
          layer_dense(units = 5, activation="relu") %>%
          layer_dense(units=1, activation="sigmoid") 
          
#Specify the learning rate for stochastic gradient descent
opt = optimizer_adam(lr = learning_rate)

#Compile the model, using binary cross-entropy to define loss. Measure accuracy during training.
model_3 %>% compile(optimizer=opt, loss='binary_crossentropy', metrics= list('accuracy'))         

#Fit the model
model_3 %>% fit(x = as.matrix(df_train[,c('x1','x2')]),
                y = df_train$y,
                epochs=num_epochs,
                batch_size=batch_size,
                )  

#add to list 
models[[3]] = model_3
```

## Calculate output and make decisions for each model on test set
```{r}
#Predict on test data. Note how easy this is to do in Keras.
preds = matrix(NA,ncol = 3 , nrow = nrow(df_test))

for (i in 1:length(models)){
  
  #retrieve model
  model = models[[i]]
  
  preds[,i] = predict(model,as.matrix(df_test[,c('x1','x2')]))
} 

#Set the classification threshold to 0.5
threshold = 0.5

#Make label predictions based on the classification threshold
y_preds = (preds >= threshold)*1

```


### Visualize test predictions for each model
```{r}
df_test %>%
    ggplot(aes(x = x1, y = x2))+
    geom_point(color = ifelse(y_preds[,1]==1,'blue','green'))+
    labs(title = 'Model 1')
df_test %>%
    ggplot(aes(x = x1, y = x2))+
    geom_point(color = ifelse(y_preds[,2]==1,'blue','green'))+
    labs(title = 'Model 2')
df_test %>%
    ggplot(aes(x = x1, y = x2))+
    geom_point(color = ifelse(y_preds[,3]==1,'blue','green'))+
    labs(title = 'Model 3')
```

## Calculate metrics for each model on test set
```{r}
accs = rep(NA,length(models))
precisions = rep(NA,length(models))
recalls = rep(NA,length(models))
f_scores = rep(NA,length(models))

for(i in 1:length(models)){
  c(true_positives, true_negatives,false_positives, false_negatives) %<-% confusion(df_test$y, preds[,i], threshold,verbose = F)
  c(precisions[i], recalls[i]) %<-% precision_and_recall(true_positives, true_negatives,false_positives, false_negatives)
  f_scores[i] = f_score(precisions[i],recalls[i])
  accs[i] = mean(df_test$y == y_preds[,i])
}
cat("Accuracy: ",accs,"\n Precision: ",precisions,"\n Recalls: ",recalls,"\n F-scores: ",f_scores)
```

## Calculate ROC and AUC for the best model
```{r}
#Consider 100 thresholds between 0 and 1
num_thresholds = 100
thresholds = seq(0,1,length.out = num_thresholds)

#Allocate space for the four metrics of the confusion matrix,
#as well as for precision and recall
fp = rep(NA,num_thresholds)
fn = rep(NA,num_thresholds)
tp = rep(NA,num_thresholds)
tn = rep(NA,num_thresholds)
precision = rep(NA,num_thresholds)
recall = rep(NA,num_thresholds)

#Loop over the thresholds, calculate the confusion matrix as well as precision and recall
for (i in 1:num_thresholds){
    
    c(tp[i], tn[i],fp[i], fn[i]) %<-% confusion(df_test$y, preds[,3], thresholds[i],verbose = F)
    c(precision[i], recall[i]) %<-% precision_and_recall(tp[i], tn[i],fp[i], fn[i],verbose = F)
    }
```

## ROC Curve
```{r}
fpr = fp/(fp+tn)
auc = ROC(fpr, recall, viz = T)
auc$plot
auc$value
```

## Train 5 times the best model

```{r}
n_init = 5

preds_model_3 = matrix(NA,nrow = nrow(df_test),ncol = n_init)

for (i in 1:n_init){
  
model = keras_model_sequential()
model = model %>% 
          layer_dense(units = 10, activation="relu") %>%
          layer_dense(units = 10, activation="relu") %>%
          layer_dense(units = 10, activation="relu") %>%
          layer_dense(units = 5, activation="relu") %>%
          layer_dense(units=1, activation="sigmoid") 
          
#Specify the learning rate for stochastic gradient descent
opt = optimizer_adam(lr = learning_rate)

#Compile the model, using binary cross-entropy to define loss. Measure accuracy during training.
model %>% compile(optimizer=opt, loss='binary_crossentropy', metrics= list('accuracy'))         

#Fit the model
model %>% fit(x = as.matrix(df_train[,c('x1','x2')]),
                y = df_train$y,
                epochs=num_epochs,
                batch_size=batch_size,
                )  
preds_model_3[,i] = predict(model,as.matrix(df_test[,c('x1','x2')]))
}
```

## Average over the models output and then make decisions. Print metrics
```{r}
#average over the models
avg_preds = rowMeans(preds_model_3)

#make decisions
y_pred = (avg_preds >= threshold)*1

#calculate matrics
c(true_positives, true_negatives,false_positives, false_negatives) %<-% confusion(df_test$y, avg_preds, threshold,verbose = F)
c(precision, recall) %<-% precision_and_recall(true_positives, true_negatives,false_positives, false_negatives)
f = f_score(precision,recall)
acc = mean(df_test$y == y_pred)

cat("Accuracy: ",acc,"\n",
    "Precision: ",precision,'\n',
    "Recall: ",recall,"\n",
    "f-score: ",f)
```


