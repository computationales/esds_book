---
title: "Exercise 04 - Solution"
output: html_document
---

# Data Scraping

**1. Get the data** a. Following the steps described in the tutorial, get the maximal length of the species *Salvelinus alpinus* and the *Salmo trutta* using an API. After fetching the values create a table to store these values in one dataframe. b. Get the IUCN Status and eggs shape for *Salvelinus alpinus* and *Salmo trutta* using web scraping. Again follow the same steps you learned in the tutorial. In the end, add the new information to the dataframe.

```{r}
## 1a.
# We start by loading the packages.
lib_vect <- c("RCurl", "XML", "raster", "rfishbase", "rgdal")
sapply(lib_vect,library,character.only=TRUE)

# First, we will directly fetch the maximum length using package rfishbase and calling function species.

# Maximum length of Salvelinus alpinus.
data_SA <- species("Salvelinus alpinus")
length_max_SA <- species("Salvelinus alpinus", fields=c("Length"))
length_max_SA <- length_max_SA$Length
length_max_SA

# Maximum length of Salmo trutta.
data_ST <- species("Salmo trutta") 
length_max_ST <- species("Salmo trutta", fields=c("Length"))
length_max_ST <- length_max_ST$Length
length_max_ST

# Now we will store the values in a dataframe.
table_SA_ST <- data.frame(length_max_SA,length_max_ST)
table_SA_ST

## 1b.
# To get the IUCN status and egg shape we will name our variables same as the species().
x <- "Salvelinus-alpinus"
y <- "Salmo-trutta"

# Next, we use the function paste() to convert its arguments to character strings and concatenate them to get the link of the webpage from which we are going to extract the data.
url1 <- paste("http://www.fishbase.de/summary/",x,".html",sep="")
url2 <- paste("http://www.fishbase.de/summary/",y,".html",sep="")

# We will use getURLContent() to retrieve the source of a webpage, which is especially useful for retrieving pages for data processing. We will apply the function htmlParse() to obtain an R object.
fishbase_SA <- htmlParse(getURLContent(url1, followlocation=TRUE)) 
fishbase_ST <- htmlParse(getURLContent(url2, followlocation=TRUE)) 

# get the information in the nodes "//div " and //span 
fishbase_div_SA <-getNodeSet(fishbase_SA, "//div ")  
fishbase_span_SA <- getNodeSet(fishbase_SA, "//span ") 
fishbase_div_ST <-getNodeSet(fishbase_ST, "//div ") 
fishbase_span_ST <- getNodeSet(fishbase_ST, "//span ")

# Now we are ready to fetch the IUCN status. We will first get the IUCN Status of Salvelinus-alpinus. Function ‘which()’ is used to find the position of the elements we are looking for and then use regexec() to search for matches to the argument pattern within each element of a character vector.

SA_IUCN  <-which(sapply(lapply(fishbase_div_SA,xmlValue),function(x)
  {regexec(pattern="IUCN", x)[[1]][1]})>0) # look for the pattern IUCN

if(length(SA_IUCN)==0){ # run the loop to get the IUCN status if non-empty otherwise set it to NA
  IUCN_status="NA"
} else {
  d1_IUCN_SA <- xmlValue(fishbase_div_SA[[SA_IUCN[length(SA_IUCN)]]])
} 
d1_IUCN_SA 

# From above we only need an IUCN status which is VU. So we are going to use unlist() to produce a vector which contains all the atomic components that occurs in the pattern (the pattern [[:alpha:]]+ is used to get the alphabetic characters) and regmatches() is used to extract or replace matched substrings from data obtained by gregexpr(). As already mentioned in the tutorial, the function gregexpr() does the same thing as regexec(), except that its returned object is a list rather than a vector.
IUCN_SA <- unlist(regmatches(d1_IUCN_SA,gregexpr(pattern= "[[:alpha:]]+)",   d1_IUCN_SA)))
IUCN_status_SA <- sub(pattern="[[:punct:]]",replacement="",IUCN_SA[1] ) 
IUCN_status_SA

# Next we do the same for IUCN Status of Salmo-trutta.
ST_IUCN  <-which(sapply(lapply(fishbase_div_ST,xmlValue),function(y)
  {regexec(pattern="IUCN", y)[[1]][1]})>0)
if(length(ST_IUCN)==0){ 
  IUCN_status="NA"
} else {
  d1_IUCN_ST <- xmlValue(fishbase_div_ST[[ST_IUCN[length(ST_IUCN)]]])
} 
IUCN_ST <- unlist(regmatches(d1_IUCN_ST,gregexpr(pattern= "[[:alpha:]]+)",  d1_IUCN_ST)))
IUCN_status_ST <- sub(pattern="[[:punct:]]",replacement="",IUCN_ST[1] ) 
IUCN_status_ST

# Now, We will get the egg shape of Salvelinus-alpinus. We will use the function getHTMLLinks() to retrieve either the links within an HTML document or the collection of names of external files referenced in an HTML document. Next we need to look for the pattern FishEggInfoSummary and to do that we use the function grep().
link_list_SA <- getHTMLLinks(fishbase_SA, externalOnly = TRUE, xpQuery = "//a/@href"
, baseURL = docName(fishbase_SA)) 
eggs_link_SA <- link_list_SA[grep("FishEggInfoSummary",link_list_SA)]
eggs_link_SA <-eggs_link_SA[1]  # here we assign first object from the two fetched objects in the FishEggInfoSummary (in the tutorial you saw that both the objects are identical and we can assign any one of them arbitrarly) 
eggs_link_SA

# get rid of two dots ".."
eggs_link_SA <- gsub("..","",eggs_link_SA,fixed=T)
eggs_link_SA

# Similarly to what we did previously, we will get the content of the webpage with the function getURLContent(). We will use readHTMLTable() to read in the table in the document. Then we can extract information from the table. Again, function which() is used to find the information. As we are looking for the shape of the egg, we will pass this value.

url_egg_SA <- paste ("http://www.fishbase.org/",eggs_link_SA,sep="")
egg_content_SA <- getURLContent(url_egg_SA, followlocation=TRUE, .encoding="CE_UTF8")

# readHTMLTable() to read in the table in the document.
egg_table_SA <- readHTMLTable(egg_content_SA,header=TRUE,colClasses=NULL,skip.rows=integer(),
                       stringsAsFactors=FALSE,trim=TRUE,elFun=xmlValue,
                       as.data.frame=TRUE,which=integer())[[1]]

egg_shape_SA = egg_table_SA[which(egg_table_SA[,1] == "Shape of Egg"),2] # Shape of Egg
if(egg_shape_SA == "") {egg_shape_SA = "NA"} # no information about the shape- set it to NA
egg_shape_SA

# To get the egg shape of Salmo-trutta, we follow the same steps as above.
link_list_ST <- getHTMLLinks(fishbase_ST, externalOnly = TRUE, xpQuery = "//a/@href"
, baseURL = docName(fishbase_ST))
eggs_link_ST <- link_list_ST[grep("FishEggInfoSummary",link_list_ST)]
eggs_link_ST <-eggs_link_ST[1]
eggs_link_ST <- gsub("..","",eggs_link_ST,fixed=T)
url_egg_ST <- paste ("http://www.fishbase.org/",eggs_link_ST,sep="")
egg_content_ST <- getURLContent(url_egg_ST, followlocation=TRUE, .encoding="CE_UTF8")
egg_table_ST <- readHTMLTable(egg_content_ST,header=TRUE,colClasses=NULL,skip.rows=integer(),
                       stringsAsFactors=FALSE,trim=TRUE,elFun=xmlValue,
                       as.data.frame=TRUE,which=integer())[[1]]
egg_shape_ST = egg_table_ST[which(egg_table_ST[,1] == "Shape of Egg"),2]   # Shape of Egg
if(egg_shape_ST == "") {egg_shape_ST = "NA"}
egg_shape_ST

# We can see that there is no data about the shape of the egg for both the species. We will store this information in a dataframe.
table_IUCN_Egg_Shape <- data.frame(IUCN_status_SA,IUCN_status_ST,egg_shape_SA,  egg_shape_ST)
table_IUCN_Egg_Shape
```

------------------------------------------------------------------------

**2. Get all the species in a family and the IUCN status** a. Your next task is to get all the species in the family *'Neoscopelidae'* and print the first 5 elements of the family. b. Extract the 'Native Exotic Status' of all the species from France. Then end get the unique values of the Native Exotic Status. For this task you will need to use the file *'ex02_data.csv'*. c. Now, use the information you got above to plot the proportion of species in each category for France.

```{r}
## 2a.
# We start by naming our vector same as the family ‘Neoscopelidae’.
neo <- "Neoscopelidae"
url_neo <- paste("http://www.fishbase.org/Nomenclature/FamilySearchList.php?Family=", neo,sep="") # get the url content
Content_Neo <- getURLContent(url_neo, followlocation=TRUE) 
# create a dataframe of the fetched content above using readHTMLTable()
neo_df <- data.frame(readHTMLTable(Content_Neo,header=NA,colClasses=NULL,skip.rows=integer()
,trim =TRUE,elFun=xmlValue,as.data.frame=TRUE,which=integer()))
# change the values in the dataframe to charcater values 
sp_per_family_Neo <- as.character(neo_df[,1])
sp_per_family_Neo <- gsub(" ","-",sp_per_family_Neo) # fill the gap with "-"
sp_per_family_Neo[1:5] # call the first five elements

## 2b. 
# We will first read the data set and then fetch the all the data related to France and then we will look for the Native-Exotic status.
dataset <- read.csv("../data/ex02_data.csv")  # read the table 
subset <- dataset[grep("France", dataset$Country),] # extract the data related to France
sp_france <- subset$X3.Native.Exotic.Status # extract the Native-Exotic status
unique(sp_france)

# Now, we plot the proprortion of exotic and native species in France.
number_nv <- length(which(subset$X3.Native.Exotic.Status == "native"))
number_ex <- length(which(subset$X3.Native.Exotic.Status == "exotic"))
slices <- c(number_nv, number_ex)
lbls <- c("native","exotic")
pie(slices, labels = lbls,font.main = 1, 
main = "Proportion of exotic and native species in France", col=c("green", "yellow"))
```

------------------------------------------------------------------------

**3. Extract the mean temperature for *Coregonus lavaretus* and *Salvelinus alpinus* using the function `stocks()` from `rfishbase` package and store the values in a new dataframe.**

```{r}
## 3.
# We first get the minimun and maximum temperature of species Coregonus lavaretus and Salvelinus alpinus. To fetch the temperatures we call the function stocks(). Then we take the mean of the fetched temperatures.
temperature_CL <- rowMeans(stocks("Coregonus lavaretus", c("TempMin", "TempMax")))
temperature_SA <- rowMeans(stocks("Salvelinus alpinus", c("TempMin", "TempMax")))

# store the data in a table
table_CL_SA <- data.frame(temperature_CL,temperature_SA)
table_CL_SA
```
