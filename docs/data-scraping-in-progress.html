<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 04_Data_Scraping [in progress] | Environmental Systems Data Science</title>
  <meta name="description" content="Text book and exercises. ETH Zürich" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 04_Data_Scraping [in progress] | Environmental Systems Data Science" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Text book and exercises. ETH Zürich" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 04_Data_Scraping [in progress] | Environmental Systems Data Science" />
  
  <meta name="twitter:description" content="Text book and exercises. ETH Zürich" />
  

<meta name="author" content="Loïc Pellissier, Joshua Payne, Benjamin Stocker" />


<meta name="date" content="2021-02-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data-variety.html"/>
<link rel="next" href="catch-up.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Environmental Systems Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="primers.html"><a href="primers.html"><i class="fa fa-check"></i><b>2</b> Primers</a></li>
<li class="chapter" data-level="3" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>3</b> Data wrangling</a></li>
<li class="chapter" data-level="4" data-path="data-variety.html"><a href="data-variety.html"><i class="fa fa-check"></i><b>4</b> Data variety</a>
<ul>
<li class="chapter" data-level="4.1" data-path="data-variety.html"><a href="data-variety.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="data-variety.html"><a href="data-variety.html#overview"><i class="fa fa-check"></i><b>4.1.1</b> Overview</a></li>
<li class="chapter" data-level="4.1.2" data-path="data-variety.html"><a href="data-variety.html#learning-objectives"><i class="fa fa-check"></i><b>4.1.2</b> Learning objectives</a></li>
<li class="chapter" data-level="4.1.3" data-path="data-variety.html"><a href="data-variety.html#key-points-of-the-lecture"><i class="fa fa-check"></i><b>4.1.3</b> Key points of the lecture</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="data-variety.html"><a href="data-variety.html#tutorial"><i class="fa fa-check"></i><b>4.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="data-variety.html"><a href="data-variety.html#overview-1"><i class="fa fa-check"></i><b>4.2.1</b> Overview</a></li>
<li class="chapter" data-level="4.2.2" data-path="data-variety.html"><a href="data-variety.html#modis-remote-download"><i class="fa fa-check"></i><b>4.2.2</b> MODIS remote download</a></li>
<li class="chapter" data-level="4.2.3" data-path="data-variety.html"><a href="data-variety.html#points-on-the-globe"><i class="fa fa-check"></i><b>4.2.3</b> Points on the globe</a></li>
<li class="chapter" data-level="4.2.4" data-path="data-variety.html"><a href="data-variety.html#shapefiles"><i class="fa fa-check"></i><b>4.2.4</b> Shapefiles</a></li>
<li class="chapter" data-level="4.2.5" data-path="data-variety.html"><a href="data-variety.html#rasters"><i class="fa fa-check"></i><b>4.2.5</b> Rasters</a></li>
<li class="chapter" data-level="4.2.6" data-path="data-variety.html"><a href="data-variety.html#key-points-of-the-tutorial"><i class="fa fa-check"></i><b>4.2.6</b> Key points of the tutorial</a></li>
<li class="chapter" data-level="4.2.7" data-path="data-variety.html"><a href="data-variety.html#bonus-species-occurrence-trait-data-and-pcas"><i class="fa fa-check"></i><b>4.2.7</b> Bonus: Species Occurrence, Trait Data and PCAs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data-scraping-in-progress.html"><a href="data-scraping-in-progress.html"><i class="fa fa-check"></i><b>5</b> 04_Data_Scraping [in progress]</a>
<ul>
<li class="chapter" data-level="5.1" data-path="data-scraping-in-progress.html"><a href="data-scraping-in-progress.html#introduction-and-learning-objectives"><i class="fa fa-check"></i><b>5.1</b> 1. Introduction and learning objectives</a></li>
<li class="chapter" data-level="5.2" data-path="data-scraping-in-progress.html"><a href="data-scraping-in-progress.html#summary-of-the-theory"><i class="fa fa-check"></i><b>5.2</b> 2. Summary of the theory</a></li>
<li class="chapter" data-level="5.3" data-path="data-scraping-in-progress.html"><a href="data-scraping-in-progress.html#case-study---web-scraping-on-fishbase"><i class="fa fa-check"></i><b>5.3</b> 3. Case Study - Web Scraping on FishBase</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="data-scraping-in-progress.html"><a href="data-scraping-in-progress.html#the-fishbase-website"><i class="fa fa-check"></i><b>5.3.1</b> 3.1 The FishBase website</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="data-scraping-in-progress.html"><a href="data-scraping-in-progress.html#hands-on"><i class="fa fa-check"></i><b>5.4</b> Hands on</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="data-scraping-in-progress.html"><a href="data-scraping-in-progress.html#preliminaries-packages"><i class="fa fa-check"></i><b>5.4.1</b> 3.2 Preliminaries (Packages)</a></li>
<li class="chapter" data-level="5.4.2" data-path="data-scraping-in-progress.html"><a href="data-scraping-in-progress.html#reading-the-content-of-fishbase"><i class="fa fa-check"></i><b>5.4.2</b> 3.3 Reading the content of FishBase</a></li>
<li class="chapter" data-level="5.4.3" data-path="data-scraping-in-progress.html"><a href="data-scraping-in-progress.html#getting-a-numerical-value-from-fishbase"><i class="fa fa-check"></i><b>5.4.3</b> 3.4 Getting a numerical value from FishBase</a></li>
<li class="chapter" data-level="5.4.4" data-path="data-scraping-in-progress.html"><a href="data-scraping-in-progress.html#getting-a-block-of-text-value-from-fishbase"><i class="fa fa-check"></i><b>5.4.4</b> 3.5 Getting a block of text value from FishBase</a></li>
<li class="chapter" data-level="5.4.5" data-path="data-scraping-in-progress.html"><a href="data-scraping-in-progress.html#reading-a-table-from-a-website"><i class="fa fa-check"></i><b>5.4.5</b> 3.6 Reading a table from a website</a></li>
<li class="chapter" data-level="5.4.6" data-path="data-scraping-in-progress.html"><a href="data-scraping-in-progress.html#r-interface-to-fishbase"><i class="fa fa-check"></i><b>5.4.6</b> 3.7 R interface to FishBase</a></li>
<li class="chapter" data-level="5.4.7" data-path="data-scraping-in-progress.html"><a href="data-scraping-in-progress.html#summary"><i class="fa fa-check"></i><b>5.4.7</b> 3.8 Summary</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="data-scraping-in-progress.html"><a href="data-scraping-in-progress.html#case-study-species-richness-and-red-list-species-proportions"><i class="fa fa-check"></i><b>5.5</b> 4. Case Study: Species richness and Red List species proportions</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="data-scraping-in-progress.html"><a href="data-scraping-in-progress.html#getting-all-the-species-in-a-family"><i class="fa fa-check"></i><b>5.5.1</b> 4.1 Getting all the species in a family</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="data-scraping-in-progress.html"><a href="data-scraping-in-progress.html#references"><i class="fa fa-check"></i><b>5.6</b> 5. References</a></li>
<li class="chapter" data-level="5.7" data-path="data-scraping-in-progress.html"><a href="data-scraping-in-progress.html#exercise"><i class="fa fa-check"></i><b>5.7</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="catch-up.html"><a href="catch-up.html"><i class="fa fa-check"></i><b>6</b> Catch-up</a></li>
<li class="chapter" data-level="7" data-path="supervised-machine-learning-basics-i.html"><a href="supervised-machine-learning-basics-i.html"><i class="fa fa-check"></i><b>7</b> Supervised machine learning basics I</a>
<ul>
<li class="chapter" data-level="7.1" data-path="supervised-machine-learning-basics-i.html"><a href="supervised-machine-learning-basics-i.html#introduction-1"><i class="fa fa-check"></i><b>7.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="supervised-machine-learning-basics-i.html"><a href="supervised-machine-learning-basics-i.html#learning-objectives-1"><i class="fa fa-check"></i><b>7.1.1</b> Learning objectives</a></li>
<li class="chapter" data-level="7.1.2" data-path="supervised-machine-learning-basics-i.html"><a href="supervised-machine-learning-basics-i.html#important-points-from-the-lecture"><i class="fa fa-check"></i><b>7.1.2</b> Important points from the lecture</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="supervised-machine-learning-basics-i.html"><a href="supervised-machine-learning-basics-i.html#tutorial-1"><i class="fa fa-check"></i><b>7.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="supervised-machine-learning-basics-i.html"><a href="supervised-machine-learning-basics-i.html#linear-regression"><i class="fa fa-check"></i><b>7.2.1</b> Linear regression</a></li>
<li class="chapter" data-level="7.2.2" data-path="supervised-machine-learning-basics-i.html"><a href="supervised-machine-learning-basics-i.html#k-nearest-neighbours"><i class="fa fa-check"></i><b>7.2.2</b> K-nearest neighbours</a></li>
<li class="chapter" data-level="7.2.3" data-path="supervised-machine-learning-basics-i.html"><a href="supervised-machine-learning-basics-i.html#essential-methods-for-the-modelling-process"><i class="fa fa-check"></i><b>7.2.3</b> Essential methods for the modelling process</a></li>
<li class="chapter" data-level="7.2.4" data-path="supervised-machine-learning-basics-i.html"><a href="supervised-machine-learning-basics-i.html#bonus"><i class="fa fa-check"></i><b>7.2.4</b> Bonus</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="supervised-machine-learning-methods-ii.html"><a href="supervised-machine-learning-methods-ii.html"><i class="fa fa-check"></i><b>8</b> Supervised machine learning methods II</a></li>
<li class="chapter" data-level="9" data-path="application-1-variable-selection.html"><a href="application-1-variable-selection.html"><i class="fa fa-check"></i><b>9</b> Application 1: Variable selection</a>
<ul>
<li class="chapter" data-level="9.1" data-path="application-1-variable-selection.html"><a href="application-1-variable-selection.html#introduction-2"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="application-1-variable-selection.html"><a href="application-1-variable-selection.html#warm-up-1-nested-for-loop"><i class="fa fa-check"></i><b>9.2</b> Warm-up 1: Nested for-loop</a></li>
<li class="chapter" data-level="9.3" data-path="application-1-variable-selection.html"><a href="application-1-variable-selection.html#warm-up-2-find-the-best-single-predictor"><i class="fa fa-check"></i><b>9.3</b> Warm-up 2: Find the best single predictor</a></li>
<li class="chapter" data-level="9.4" data-path="application-1-variable-selection.html"><a href="application-1-variable-selection.html#full-stepwise-regression"><i class="fa fa-check"></i><b>9.4</b> Full stepwise regression</a></li>
<li class="chapter" data-level="9.5" data-path="application-1-variable-selection.html"><a href="application-1-variable-selection.html#bonus-stepwise-regression-out-of-the-box"><i class="fa fa-check"></i><b>9.5</b> Bonus: Stepwise regression out-of-the-box</a></li>
<li class="chapter" data-level="9.6" data-path="application-1-variable-selection.html"><a href="application-1-variable-selection.html#warm-up-2-find-the-best-single-predictor-1"><i class="fa fa-check"></i><b>9.6</b> Warm-up 2: Find the best single predictor</a></li>
<li class="chapter" data-level="9.7" data-path="application-1-variable-selection.html"><a href="application-1-variable-selection.html#full-stepwise-regression-1"><i class="fa fa-check"></i><b>9.7</b> Full stepwise regression</a></li>
<li class="chapter" data-level="9.8" data-path="application-1-variable-selection.html"><a href="application-1-variable-selection.html#bonus-stepwise-regression-out-of-the-box-1"><i class="fa fa-check"></i><b>9.8</b> <span>BONUS</span> Stepwise regression out-of-the-box</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="xxx.html"><a href="xxx.html"><i class="fa fa-check"></i><b>10</b> XXX</a></li>
<li class="chapter" data-level="11" data-path="xxx-1.html"><a href="xxx-1.html"><i class="fa fa-check"></i><b>11</b> XXX</a></li>
<li class="chapter" data-level="12" data-path="xxx-2.html"><a href="xxx-2.html"><i class="fa fa-check"></i><b>12</b> XXX</a></li>
<li class="chapter" data-level="13" data-path="xxx-3.html"><a href="xxx-3.html"><i class="fa fa-check"></i><b>13</b> XXX</a></li>
<li class="chapter" data-level="14" data-path="xxx-4.html"><a href="xxx-4.html"><i class="fa fa-check"></i><b>14</b> XXX</a></li>
<li class="chapter" data-level="15" data-path="xxx-5.html"><a href="xxx-5.html"><i class="fa fa-check"></i><b>15</b> XXX</a></li>
<li class="chapter" data-level="" data-path="references-1.html"><a href="references-1.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Environmental Systems Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="data_scraping-in-progress" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> 04_Data_Scraping [in progress]</h1>
<hr />
<div id="introduction-and-learning-objectives" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> 1. Introduction and learning objectives</h2>
<p>This exercise covers <em>data scraping</em> in R and yes, this is not a typo it is indeed spelt <em>scraping</em> (to gather or extract) not <em>scrapping</em> (to get rid of). The goal is to download and convert online data into a structured format that can be easily accessed and modified in R. As a case study, we will scrape data from a website containing various kinds of information about fish species, called <a href="https://www.fishbase.in/search.php">FishBase</a>. We will first extract the useful information about fish species and their families from the scrapped data. Then, we will learn how to read a table in HTML document and how to generate a new table with the extracted information. Later, we will clean our data and plot the relationship among different species with respect to its proportion and surface area. At the end we will run the model and make the predictions about fish richness.</p>
<hr />
</div>
<div id="summary-of-the-theory" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> 2. Summary of the theory</h2>
<p>Let us first have a brief review of the main concept of the lecture.</p>
<p>The web is the largest source of information and often free to access. In some cases the information is already presented in a nice format and can be easily copied into an excel spreadsheet.
However, this is often not the case and data-sets are only present in a format that are not easy to download or modify. Copying data from different sub pages and blocks manually is a tedious, slow and error prone approach. We therefore need a different technique to access such data in a more automated and efficient way.
Web scraping is a popular technique to extract information from the web. It allows us to get unstructured data from the web and convert it into readable and structured formats. This structured data can then be further used as training, validation or test data sets for our machine learning algorithms.</p>
<div style="border: 2px black solid; border-radius: 7px; padding:10px">
<p>We will now review some of the most important concepts and protocols used on websites.</p>
<ul>
<li><p>HTTP: The <b>H</b>yper<b>t</b>ext <b>T</b>ransfer <b>P</b>rotocol is widely used protocol in information systems. Hypertext documents include hyperlinks to other resources that a user can easily access just by a mouse click or by tapping the screen in a web browser.</p></li>
<li><p>HTML: The <b>H</b>yper<b>t</b>ext <b>M</b>arkup <b>L</b>anguage is markup language as the name suggests and is often used to build websites and describes their content and structure. HTML is organized using tags, which are surrounded by &lt; &gt; symbols. One problem when scraping HTML based websites is that not all the websites have the same html structure, different sites vary in their structure, request tags and HTML tags.</p></li>
<li><p>XML: The e<b>X</b>tensible <b>M</b>arkup <b>L</b>anguage has certain similarities to HTML but the format is generally easier to read for machines. While HTML has a number of pre-defined tags, those are extensible in XML. This means that it allows to define and control the meaning of the elements contained in a document or text.</p></li>
<li><p>API: An <b>A</b>pplication <b>P</b>rogramming <b>I</b>nterface is a set of procedures and communication protocols that provide access to the data of an application, operating system or other services. Both APIs and web scraping are used to retrieve data from websites, but their methodology differs substantially. APIs give us direct access to the data we would want, but they are limited to the corresponding website. As a result, we might find us in a scenario where there might not be an API to access the data we want. In these scenarios, web scrapping would allow us to access the data as long as it is available on a website. Hence APIs are very source/website specific and we can only do what is already implemented but in a clean fashion, while scrapping is more flexible and can be applied (nearly) everywhere but we have to handle all the formatting, inconsistencies, extraction, etc. by ourself.</p></li>
</ul>
</div>
<hr />
</div>
<div id="case-study---web-scraping-on-fishbase" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> 3. Case Study - Web Scraping on FishBase</h2>
<p>We will now demonstrate the principles of web scraping using a simple case study. We will extract fish occurrence data from an online database and perform some basic correlations with the obtained data. We will quickly introduce our data source, the FishBase database.</p>
<div id="the-fishbase-website" class="section level3" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> 3.1 The FishBase website</h3>
<p><a href="https://www.fishbase.in/search.php">FishBase</a> is a global species database of fish species. It provides data of various fish species, including information on taxonomy, geographical distribution, biometrics and morphology, behaviour and habitats, ecology and population dynamics as well as reproductive, metabolic and genetic data. Different tools, such as trophic pyramids, identification keys, biogeographical modelling and fishery statistics can be accessed on the website. Furthermore, direct species level links to information in other databases such as LarvalBase, GenBank, the IUCN Red List and the Catalog of Fishes exist. As of November 2018, FishBase included descriptions of 34,000 species and subspecies.
<img src="../data/images/screen.png" alt="Screenshot of the FishBase webpage for the species Coregonus lavaretus, a member of the family Salmonidae. It is widespread in freshwater systems from central and northwest Europe to Siberia." />
<b>Figure1.</b> Screenshot of the FishBase webpage for the species <em>Coregonus lavaretus</em>, a member of the family Salmonidae. It is widespread in freshwater systems from central and northwest Europe to Siberia.</p>
<p>As shown in figure 1, the website contains lots of information for each species. This information is stored in various different data types, such as:
- numbers in different formats and units (temperature ranges, latitudinal distribution)
- text blocks (description of the distribution)
- tables (fecundity, larvae information)
- pictures and videos (of the species, embedded into HTML code)</p>
<p>For a better understanding of the following R code, you are strongly encouraged to have a look at the <a href="https://fishbase.org">FishBase</a> website in your browser.</p>
<p>In the next sections you will learn how to deal with the complex data types. A careful approach is required when extracting and downloading information from such datasets. It is an imporant first step as it will save you time looking for the important (or relevant) information and will make the application of machine learning algorithms more straight forward.</p>
<hr />
</div>
</div>
<div id="hands-on" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Hands on</h2>
<div id="preliminaries-packages" class="section level3" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> 3.2 Preliminaries (Packages)</h3>
<p>We will now load the packages necessary to perform the web scraping on FishBase, namely <b>RCurl</b> and <b>XML</b>. Since we will also use the <b>raster</b> and <b>rgdal</b> packages for spatial visualisation later in this tutorial, we will load them here in the beginning.</p>
<p>The package RCurl provides functions to allow us to compose general HTTP requests and provides convenient functions to fetch URLs via get and post requests and process the results returned by the web server. The package XML give us approaches for both <b>reading</b> (get request) and <b>creating</b> (post request) XML (and HTML) documents, both locally and on the web via HTTP.</p>
<hr />
<p>Before we proceed further, we would like to introduce function <strong>lapply()</strong> and <strong>sapply()</strong>.</p>
<p><strong>lapply()</strong> : lapply returns a list of the same length as X, each element of which is the result of applying FUN (Function applied to each element of x) to the corresponding element of X. X is a vector (atomic or list) or an expression object. <code>lapply()</code> takes vector or data frame as input and gives output in list. The <em><strong>l</strong></em> in <code>lapply()</code> stands for list.</p>
<p><code>lapply(X, FUN)</code></p>
<p>Arguments:</p>
<p>-<code>X</code>: A vector or an object</p>
<p>-<code>FUN</code>: Function applied to each element of x</p>
<p><strong>For example :</strong> A simple example is to change the string value of a matrix to lower case with tolower function. We construct a matrix fish. The name is in upper case format.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="data-scraping-in-progress.html#cb3-1" aria-hidden="true" tabindex="-1"></a>fish <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;FAMILY&quot;</span>,<span class="st">&quot;SPECIES&quot;</span>)</span>
<span id="cb3-2"><a href="data-scraping-in-progress.html#cb3-2" aria-hidden="true" tabindex="-1"></a>fish_lower <span class="ot">&lt;-</span><span class="fu">lapply</span>(fish, tolower)</span>
<span id="cb3-3"><a href="data-scraping-in-progress.html#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(fish_lower)</span></code></pre></div>
<pre><code>## List of 2
##  $ : chr &quot;family&quot;
##  $ : chr &quot;species&quot;</code></pre>
<pre><code>List of 2
 $ : chr &quot;family&quot;
 $ : chr &quot;species&quot;</code></pre>
<p><strong>sapply()</strong> : sapply() function takes list, vector or data frame as input and gives output in vector or matrix. It is useful for operations on list objects and returns a list object of the same length as the original set. <code>sapply()</code> function does the same job as <code>lapply()</code> function but returns a vector.</p>
<hr />
<p>In the next two lines we load the packages and save them in the vector ‘lib_vec.’</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="data-scraping-in-progress.html#cb6-1" aria-hidden="true" tabindex="-1"></a>lib_vec <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;RCurl&quot;</span>, <span class="st">&quot;XML&quot;</span>, <span class="st">&quot;raster&quot;</span>, <span class="st">&quot;rgdal&quot;</span>, <span class="st">&quot;rfishbase&quot;</span>, <span class="st">&quot;tidyverse&quot;</span>, <span class="st">&quot;sf&quot;</span>)</span>
<span id="cb6-2"><a href="data-scraping-in-progress.html#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sapply</span>(lib_vec, library, <span class="at">character.only =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## Loading required package: sp</code></pre>
<pre><code>## 
## Attaching package: &#39;raster&#39;</code></pre>
<pre><code>## The following object is masked _by_ &#39;.GlobalEnv&#39;:
## 
##     area</code></pre>
<pre><code>## rgdal: version: 1.5-21, (SVN revision 1105)
## Geospatial Data Abstraction Library extensions to R successfully loaded
## Loaded GDAL runtime: GDAL 3.2.1, released 2020/12/29
## Path to GDAL shared files: /usr/local/Cellar/gdal/3.2.1/share/gdal
## GDAL binary built with GEOS: TRUE 
## Loaded PROJ runtime: Rel. 7.2.1, January 1st, 2021, [PJ_VERSION: 721]
## Path to PROJ shared files: /Users/benjaminstocker/Library/Application Support/proj:/usr/local/opt/proj/share/proj:/usr/local/Cellar/proj/7.2.1/share/proj
## PROJ CDN enabled: FALSE
## Linking to sp version:1.4-5
## To mute warnings of possible GDAL/OSR exportToProj4() degradation,
## use options(&quot;rgdal_show_exportToProj4_warnings&quot;=&quot;none&quot;) before loading rgdal.</code></pre>
<pre><code>## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──</code></pre>
<pre><code>## ✓ ggplot2 3.3.3     ✓ purrr   0.3.4
## ✓ tibble  3.0.6     ✓ dplyr   1.0.3
## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
## ✓ readr   1.4.0     ✓ forcats 0.5.1</code></pre>
<pre><code>## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## x tidyr::complete() masks RCurl::complete()
## x tidyr::extract()  masks raster::extract()
## x dplyr::filter()   masks stats::filter()
## x dplyr::lag()      masks stats::lag()
## x dplyr::select()   masks raster::select()</code></pre>
<pre><code>## Linking to GEOS 3.9.0, GDAL 3.2.1, PROJ 7.2.1</code></pre>
<pre><code>## $RCurl
## [1] &quot;RCurl&quot;     &quot;stats&quot;     &quot;graphics&quot;  &quot;grDevices&quot; &quot;utils&quot;     &quot;datasets&quot; 
## [7] &quot;methods&quot;   &quot;base&quot;     
## 
## $XML
## [1] &quot;XML&quot;       &quot;RCurl&quot;     &quot;stats&quot;     &quot;graphics&quot;  &quot;grDevices&quot; &quot;utils&quot;    
## [7] &quot;datasets&quot;  &quot;methods&quot;   &quot;base&quot;     
## 
## $raster
##  [1] &quot;raster&quot;    &quot;sp&quot;        &quot;XML&quot;       &quot;RCurl&quot;     &quot;stats&quot;     &quot;graphics&quot; 
##  [7] &quot;grDevices&quot; &quot;utils&quot;     &quot;datasets&quot;  &quot;methods&quot;   &quot;base&quot;     
## 
## $rgdal
##  [1] &quot;rgdal&quot;     &quot;raster&quot;    &quot;sp&quot;        &quot;XML&quot;       &quot;RCurl&quot;     &quot;stats&quot;    
##  [7] &quot;graphics&quot;  &quot;grDevices&quot; &quot;utils&quot;     &quot;datasets&quot;  &quot;methods&quot;   &quot;base&quot;     
## 
## $rfishbase
##  [1] &quot;rfishbase&quot; &quot;rgdal&quot;     &quot;raster&quot;    &quot;sp&quot;        &quot;XML&quot;       &quot;RCurl&quot;    
##  [7] &quot;stats&quot;     &quot;graphics&quot;  &quot;grDevices&quot; &quot;utils&quot;     &quot;datasets&quot;  &quot;methods&quot;  
## [13] &quot;base&quot;     
## 
## $tidyverse
##  [1] &quot;forcats&quot;   &quot;stringr&quot;   &quot;dplyr&quot;     &quot;purrr&quot;     &quot;readr&quot;     &quot;tidyr&quot;    
##  [7] &quot;tibble&quot;    &quot;ggplot2&quot;   &quot;tidyverse&quot; &quot;rfishbase&quot; &quot;rgdal&quot;     &quot;raster&quot;   
## [13] &quot;sp&quot;        &quot;XML&quot;       &quot;RCurl&quot;     &quot;stats&quot;     &quot;graphics&quot;  &quot;grDevices&quot;
## [19] &quot;utils&quot;     &quot;datasets&quot;  &quot;methods&quot;   &quot;base&quot;     
## 
## $sf
##  [1] &quot;sf&quot;        &quot;forcats&quot;   &quot;stringr&quot;   &quot;dplyr&quot;     &quot;purrr&quot;     &quot;readr&quot;    
##  [7] &quot;tidyr&quot;     &quot;tibble&quot;    &quot;ggplot2&quot;   &quot;tidyverse&quot; &quot;rfishbase&quot; &quot;rgdal&quot;    
## [13] &quot;raster&quot;    &quot;sp&quot;        &quot;XML&quot;       &quot;RCurl&quot;     &quot;stats&quot;     &quot;graphics&quot; 
## [19] &quot;grDevices&quot; &quot;utils&quot;     &quot;datasets&quot;  &quot;methods&quot;   &quot;base&quot;</code></pre>
<table>
<caption>
A matrix: 23 × 7 of type chr
</caption>
<thead>
<tr>
<th scope="col">
RCurl
</th>
<th scope="col">
XML
</th>
<th scope="col">
raster
</th>
<th scope="col">
rgdal
</th>
<th scope="col">
rfishbase
</th>
<th scope="col">
tidyverse
</th>
<th scope="col">
sf
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
sf
</td>
<td>
sf
</td>
<td>
sf
</td>
<td>
sf
</td>
<td>
sf
</td>
<td>
sf
</td>
<td>
sf
</td>
</tr>
<tr>
<td>
forcats
</td>
<td>
forcats
</td>
<td>
forcats
</td>
<td>
forcats
</td>
<td>
forcats
</td>
<td>
forcats
</td>
<td>
forcats
</td>
</tr>
<tr>
<td>
stringr
</td>
<td>
stringr
</td>
<td>
stringr
</td>
<td>
stringr
</td>
<td>
stringr
</td>
<td>
stringr
</td>
<td>
stringr
</td>
</tr>
<tr>
<td>
dplyr
</td>
<td>
dplyr
</td>
<td>
dplyr
</td>
<td>
dplyr
</td>
<td>
dplyr
</td>
<td>
dplyr
</td>
<td>
dplyr
</td>
</tr>
<tr>
<td>
purrr
</td>
<td>
purrr
</td>
<td>
purrr
</td>
<td>
purrr
</td>
<td>
purrr
</td>
<td>
purrr
</td>
<td>
purrr
</td>
</tr>
<tr>
<td>
readr
</td>
<td>
readr
</td>
<td>
readr
</td>
<td>
readr
</td>
<td>
readr
</td>
<td>
readr
</td>
<td>
readr
</td>
</tr>
<tr>
<td>
tidyr
</td>
<td>
tidyr
</td>
<td>
tidyr
</td>
<td>
tidyr
</td>
<td>
tidyr
</td>
<td>
tidyr
</td>
<td>
tidyr
</td>
</tr>
<tr>
<td>
tibble
</td>
<td>
tibble
</td>
<td>
tibble
</td>
<td>
tibble
</td>
<td>
tibble
</td>
<td>
tibble
</td>
<td>
tibble
</td>
</tr>
<tr>
<td>
ggplot2
</td>
<td>
ggplot2
</td>
<td>
ggplot2
</td>
<td>
ggplot2
</td>
<td>
ggplot2
</td>
<td>
ggplot2
</td>
<td>
ggplot2
</td>
</tr>
<tr>
<td>
tidyverse
</td>
<td>
tidyverse
</td>
<td>
tidyverse
</td>
<td>
tidyverse
</td>
<td>
tidyverse
</td>
<td>
tidyverse
</td>
<td>
tidyverse
</td>
</tr>
<tr>
<td>
rfishbase
</td>
<td>
rfishbase
</td>
<td>
rfishbase
</td>
<td>
rfishbase
</td>
<td>
rfishbase
</td>
<td>
rfishbase
</td>
<td>
rfishbase
</td>
</tr>
<tr>
<td>
rgdal
</td>
<td>
rgdal
</td>
<td>
rgdal
</td>
<td>
rgdal
</td>
<td>
rgdal
</td>
<td>
rgdal
</td>
<td>
rgdal
</td>
</tr>
<tr>
<td>
raster
</td>
<td>
raster
</td>
<td>
raster
</td>
<td>
raster
</td>
<td>
raster
</td>
<td>
raster
</td>
<td>
raster
</td>
</tr>
<tr>
<td>
sp
</td>
<td>
sp
</td>
<td>
sp
</td>
<td>
sp
</td>
<td>
sp
</td>
<td>
sp
</td>
<td>
sp
</td>
</tr>
<tr>
<td>
XML
</td>
<td>
XML
</td>
<td>
XML
</td>
<td>
XML
</td>
<td>
XML
</td>
<td>
XML
</td>
<td>
XML
</td>
</tr>
<tr>
<td>
RCurl
</td>
<td>
RCurl
</td>
<td>
RCurl
</td>
<td>
RCurl
</td>
<td>
RCurl
</td>
<td>
RCurl
</td>
<td>
RCurl
</td>
</tr>
<tr>
<td>
stats
</td>
<td>
stats
</td>
<td>
stats
</td>
<td>
stats
</td>
<td>
stats
</td>
<td>
stats
</td>
<td>
stats
</td>
</tr>
<tr>
<td>
graphics
</td>
<td>
graphics
</td>
<td>
graphics
</td>
<td>
graphics
</td>
<td>
graphics
</td>
<td>
graphics
</td>
<td>
graphics
</td>
</tr>
<tr>
<td>
grDevices
</td>
<td>
grDevices
</td>
<td>
grDevices
</td>
<td>
grDevices
</td>
<td>
grDevices
</td>
<td>
grDevices
</td>
<td>
grDevices
</td>
</tr>
<tr>
<td>
utils
</td>
<td>
utils
</td>
<td>
utils
</td>
<td>
utils
</td>
<td>
utils
</td>
<td>
utils
</td>
<td>
utils
</td>
</tr>
<tr>
<td>
datasets
</td>
<td>
datasets
</td>
<td>
datasets
</td>
<td>
datasets
</td>
<td>
datasets
</td>
<td>
datasets
</td>
<td>
datasets
</td>
</tr>
<tr>
<td>
methods
</td>
<td>
methods
</td>
<td>
methods
</td>
<td>
methods
</td>
<td>
methods
</td>
<td>
methods
</td>
<td>
methods
</td>
</tr>
<tr>
<td>
base
</td>
<td>
base
</td>
<td>
base
</td>
<td>
base
</td>
<td>
base
</td>
<td>
base
</td>
<td>
base
</td>
</tr>
</tbody>
</table>
<p>To get information about the packages we can type the following command in the console.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="data-scraping-in-progress.html#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">help</span>(<span class="at">package =</span> <span class="st">&quot;XML&quot;</span>)</span></code></pre></div>
<p>For data scraping in R one can also use ‘rjson’ to convert R objects into JSON objects and vice-versa. Another option as we will see later is to use APIs.</p>
<hr />
</div>
<div id="reading-the-content-of-fishbase" class="section level3" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> 3.3 Reading the content of FishBase</h3>
<p>We are now ready to extract data from <a href="https://www.fishbase.de" class="uri">https://www.fishbase.de</a>. We want to get data about the <em>Coregonus lavaretus</em>. We can create the object x and assign the value same as the species to keep the flexibility. If we want to get data about other species we can generate a new object or can also assign new value to the object <em>x</em> with the desired species name.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="data-scraping-in-progress.html#cb17-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="st">&quot;Coregonus-lavaretus&quot;</span></span></code></pre></div>
<p>Next, we use the function <code>paste()</code> to convert its arguments to character strings and concatenate them to get the link of the webpage from which we are going to extract the data. We concatenate the URL in order to get the webpage with the summary of the species <em>Coregonus-lavaretus</em>. We do not put any separation between the arguments, so we use <code>sep = ""</code>.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="data-scraping-in-progress.html#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># to keep the code &#39;flexible&#39;, you can see here that x is used to define the species</span></span>
<span id="cb18-2"><a href="data-scraping-in-progress.html#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co"># this way we can easily change the species without having to always and the latin name to the code</span></span>
<span id="cb18-3"><a href="data-scraping-in-progress.html#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="data-scraping-in-progress.html#cb18-4" aria-hidden="true" tabindex="-1"></a>url1 <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">&quot;http://www.fishbase.de/summary/&quot;</span>, x ,<span class="st">&quot;.html&quot;</span>,<span class="at">sep=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<p>For url1 we could also directly use <a href="http://www.fishbase.de/summary/Coregonus-lavaretus" class="uri">http://www.fishbase.de/summary/Coregonus-lavaretus</a>, but then we would loose flexibility if we want to look for information about other species.</p>
<div style="background-color:rgba(0, 200, 0, 0.5);border-radius: 7px; padding:10px">
<pre><code>&lt;b&gt;Checkpoint&lt;/b&gt;&lt;br/&gt;
You can try to do the same for different species by changing the value of object x or by directly providing the address of any other species into the url. </code></pre>
</div>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="data-scraping-in-progress.html#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># your code </span></span></code></pre></div>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="data-scraping-in-progress.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Solution</span></span>
<span id="cb21-2"><a href="data-scraping-in-progress.html#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="data-scraping-in-progress.html#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># set the object x1 with the species name</span></span>
<span id="cb21-4"><a href="data-scraping-in-progress.html#cb21-4" aria-hidden="true" tabindex="-1"></a>x1<span class="ot">&lt;-</span> <span class="st">&quot;Salvelinus alpinus&quot;</span></span>
<span id="cb21-5"><a href="data-scraping-in-progress.html#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="data-scraping-in-progress.html#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co"># concatenate the url</span></span>
<span id="cb21-7"><a href="data-scraping-in-progress.html#cb21-7" aria-hidden="true" tabindex="-1"></a>url11 <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">&quot;http://www.fishbase.de/summary/&quot;</span>,x1,<span class="st">&quot;.html&quot;</span>,<span class="at">sep=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<hr />
<p>Before we continue with the tutorial let’s give a brief introduction to HTML (HyperText Markup Language).</p>
<p><strong>HTML</strong> : HTML is a primary markup language for creating websites. It consists of a series of codes used to structure texts, images, and other content to be displayed in the browser. Each HTML document is made of elements that are specified using tags. HTML elements and HTML tags are often confused. The <em>tags</em> are used to open and close the object, whereas the <em>element</em> includes both tags and its content.</p>
Let’s consider an example with the
<h1>
<p>tag:</p>
<h1>
Title of the document
</h1>
<ul>
<li>is an element, and
<h1>
,
</h1>
<ul>
<li>are tags.</li>
</ul></li>
</ul>
<p>&lt;&gt; symbol is used to open a tag or an element and &lt;/&gt; is used to close it.
HTML document has a hierarchical or tree like structure with different types of nodes as discribed in the figure. The rectangular boxes are referred as nodes. The Text node is also called as a child node of Element Node and also a leaf node as it only contains the text and no links to further nodes. Both of the Element nodes that are attached to Root Element node are called Sibling nodes of Root Element node. When we do scrapping we go through such hierarchical structure to get the content (here text). Keep in mind that every html document can vary with respect to its structure. This example is to just to provide you some knowledge about HTML document and its structure.</p>
<div class="figure">
<img src="../data/images/node-tree.png" alt="" />
<p class="caption">alt</p>
</div>
<hr />
<p>The next step is to use the <code>htmlParse()</code> function to read the html document into an R object.
To get help on functions we can type the following command in the console, remember how you also used this for getting information on the packages.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="data-scraping-in-progress.html#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">help</span>(<span class="st">&quot;htmlParse&quot;</span>)</span></code></pre></div>
<table width="100%" summary="page for xmlTreeParse {XML}">
<tr>
<td>
xmlTreeParse {XML}
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
XML Parser
</h2>
<h3>
Description
</h3>
<p>
Parses an XML or HTML file or string containing XML/HTML content, and generates an R
structure representing the XML/HTML tree. Use <code>htmlTreeParse</code> when the content is known
to be (potentially malformed) HTML.
This function has numerous parameters/options and operates quite differently
based on their values.
It can create trees in R or using internal C-level nodes, both of
which are useful in different contexts.
It can perform conversion of the nodes into R objects using
caller-specified handler functions and this can be used to
map the XML document directly into R data structures,
by-passing the conversion to an R-level tree which would then
be processed recursively or with multiple descents to extract the
information of interest.
</p>
<p>
<code>xmlParse</code> and <code>htmlParse</code> are equivalent to the
<code>xmlTreeParse</code> and <code>htmlTreeParse</code> respectively,
except they both use a default value for the <code>useInternalNodes</code> parameter
of <code>TRUE</code>, i.e. they working with and return internal
nodes/C-level nodes. These can then be searched using
XPath expressions via <code>xpathApply</code> and
<code>getNodeSet</code>.
</p>
<p>
<code>xmlSchemaParse</code> is a convenience function for parsing an XML schema.
</p>
<h3>
Usage
</h3>
<pre>
xmlTreeParse(file, ignoreBlanks=TRUE, handlers=NULL, replaceEntities=FALSE,
             asText=FALSE, trim=TRUE, validate=FALSE, getDTD=TRUE,
             isURL=FALSE, asTree = FALSE, addAttributeNamespaces = FALSE,
             useInternalNodes = FALSE, isSchema = FALSE,
             fullNamespaceInfo = FALSE, encoding = character(),
             useDotNames = length(grep("^\\.", names(handlers))) &gt; 0,
             xinclude = TRUE, addFinalizer = TRUE, error = xmlErrorCumulator(),
             isHTML = FALSE, options = integer(), parentFirst = FALSE)

xmlInternalTreeParse(file, ignoreBlanks=TRUE, handlers=NULL, replaceEntities=FALSE,
             asText=FALSE, trim=TRUE, validate=FALSE, getDTD=TRUE,
             isURL=FALSE, asTree = FALSE, addAttributeNamespaces = FALSE,
             useInternalNodes = TRUE, isSchema = FALSE,
             fullNamespaceInfo = FALSE, encoding = character(),
             useDotNames = length(grep("^\\.", names(handlers))) &gt; 0,
             xinclude = TRUE, addFinalizer = TRUE, error = xmlErrorCumulator(),
             isHTML = FALSE, options = integer(), parentFirst = FALSE)

xmlNativeTreeParse(file, ignoreBlanks=TRUE, handlers=NULL, replaceEntities=FALSE,
             asText=FALSE, trim=TRUE, validate=FALSE, getDTD=TRUE,
             isURL=FALSE, asTree = FALSE, addAttributeNamespaces = FALSE,
             useInternalNodes = TRUE, isSchema = FALSE,
             fullNamespaceInfo = FALSE, encoding = character(),
             useDotNames = length(grep("^\\.", names(handlers))) &gt; 0,
             xinclude = TRUE, addFinalizer = TRUE, error = xmlErrorCumulator(),
             isHTML = FALSE, options = integer(), parentFirst = FALSE)


htmlTreeParse(file, ignoreBlanks=TRUE, handlers=NULL, replaceEntities=FALSE,
             asText=FALSE, trim=TRUE, validate=FALSE, getDTD=TRUE,
             isURL=FALSE, asTree = FALSE, addAttributeNamespaces = FALSE,
             useInternalNodes = FALSE, isSchema = FALSE,
             fullNamespaceInfo = FALSE, encoding = character(),
             useDotNames = length(grep("^\\.", names(handlers))) &gt; 0,
             xinclude = TRUE, addFinalizer = TRUE, error = htmlErrorHandler,
             isHTML = TRUE, options = integer(), parentFirst = FALSE)

htmlParse(file, ignoreBlanks = TRUE, handlers = NULL, replaceEntities = FALSE, 
          asText = FALSE, trim = TRUE, validate = FALSE, getDTD = TRUE, 
           isURL = FALSE, asTree = FALSE, addAttributeNamespaces = FALSE, 
            useInternalNodes = TRUE, isSchema = FALSE, fullNamespaceInfo = FALSE, 
             encoding = character(), 
             useDotNames = length(grep("^\\.", names(handlers))) &gt; 0, 
              xinclude = TRUE, addFinalizer = TRUE, 
               error = htmlErrorHandler, isHTML = TRUE,
                options = integer(), parentFirst = FALSE) 

xmlSchemaParse(file, asText = FALSE, xinclude = TRUE, error = xmlErrorCumulator())
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>file</code>
</td>
<td>
<p>
The name of the file containing the XML contents.
This can contain ~ which is expanded to the user’s
home directory.
It can also be a URL. See <code>isURL</code>.
Additionally, the file can be compressed (gzip)
and is read directly without the user having
to de-compress (gunzip) it.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>ignoreBlanks</code>
</td>
<td>
<p>
logical value indicating whether
text elements made up entirely of white space should be included
in the resulting ‘tree.’
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>handlers</code>
</td>
<td>
<p>
Optional collection of functions
used to map the different XML nodes to R
objects. Typically, this is a named list of functions,
and a closure can be used to provide local data.
This provides a way of filtering the tree as it is being
created in R, adding or removing nodes, and generally processing
them as they are constructed in the C code.
</p>
<p>
In a recent addition to the package (version 0.99-8),
if this is specified as a single function object,
we call that function for each node (of any type) in the underlying DOM tree.
It is invoked with the new node and its parent node.
This applies to regular nodes and also comments, processing
instructions, CDATA nodes, etc. So this function must be
sufficiently general to handle them all.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>replaceEntities</code>
</td>
<td>
<p>
logical value indicating whether to substitute entity references
with their text directly. This should be left as False.
The text still appears as the value of the node, but there
is more information about its source, allowing the parse to be reversed
with full reference information.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>asText</code>
</td>
<td>
<p>
logical value indicating that the first argument,
‘file,’
should be treated as the XML text to parse, not the name of
a file. This allows the contents of documents to be retrieved
from different sources (e.g. HTTP servers, XML-RPC, etc.) and still
use this parser.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>trim</code>
</td>
<td>
<p>
whether to strip white space from the beginning and end of text strings.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>validate</code>
</td>
<td>
<p>
logical indicating whether to use a validating parser or not, or in other words
check the contents against the DTD specification. If this is true, warning
messages will be displayed about errors in the DTD and/or document, but the parsing
will proceed except for the presence of terminal errors.
This is ignored when parsing an HTML document.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>getDTD</code>
</td>
<td>
<p>
logical flag indicating whether the DTD (both internal and external)
should be returned along with the document nodes. This changes the
return type.
This is ignored when parsing an HTML document.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>isURL</code>
</td>
<td>
<p>
indicates whether the <code>file</code> argument refers to a URL
(accessible via ftp or http) or a regular file on the system.
If <code>asText</code> is TRUE, this should not be specified.
The function attempts to determine whether the
data source is a URL by using <code>grep</code>
to look for http or ftp at the start of the string.
The libxml parser handles the connection to servers,
not the R facilities (e.g. <code>scan</code>).
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>asTree</code>
</td>
<td>
<p>
this only applies when on passes a value for
the <code>handlers</code> argument and is used then to determine
whether the DOM tree should be returned or the <code>handlers</code>
object.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>addAttributeNamespaces</code>
</td>
<td>
<p>
a logical value indicating whether to
return the namespace in the names of the attributes within a node
or to omit them. If this is <code>TRUE</code>, an attribute such as
<code>xsi:type=“xsd:string”</code> is reported with the name
<code>xsi:type</code>.
If it is <code>FALSE</code>, the name of the attribute is <code>type</code>.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>useInternalNodes</code>
</td>
<td>
<p>
a logical value indicating whether
to call the converter functions with objects of class
<code>XMLInternalNode</code> rather than <code>XMLNode</code>.
This should make things faster as we do not convert the
contents of the internal nodes to R explicit objects.
Also, it allows one to access the parent and ancestor nodes.
However, since the objects refer to volatile C-level objects,
one cannot store these nodes for use in further computations within R.
They “disappear” after the processing the XML document is completed.
</p>
<p>
If this argument is <code>TRUE</code> and no handlers are provided, the
return value is a reference to the internal C-level document pointer.
This can be used to do post-processing via XPath expressions using
<code>getNodeSet</code>.
</p>
<p>
This is ignored when parsing an HTML document.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>isSchema</code>
</td>
<td>
<p>
a logical value indicating whether the document
is an XML schema (<code>TRUE</code>) and should be parsed as such using
the built-in schema parser in libxml.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>fullNamespaceInfo</code>
</td>
<td>
<p>
a logical value indicating whether
to provide the namespace URI and prefix on each node
or just the prefix. The latter (<code>FALSE</code>) is
currently the default as that was the original way the
package behaved. However, using
<code>TRUE</code> is more informative and we will make this
the default in the future.
</p>
<p>
This is ignored when parsing an HTML document.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>encoding</code>
</td>
<td>
<p>
a character string (scalar) giving the encoding for the
document. This is optional as the document should contain its own
encoding information. However, if it doesn’t, the caller can specify
this for the parser. If the XML/HTML document does specify its own
encoding that value is used regardless of any value specified by the
caller. (That’s just the way it goes!) So this is to be used
as a safety net in case the document does not have an encoding and
the caller happens to know theactual encoding.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>useDotNames</code>
</td>
<td>
<p>
a logical value
indicating whether to use the
newer format for identifying general element function handlers
with the ‘.’ prefix, e.g. .text, .comment, .startElement.
If this is <code>FALSE</code>, then the older format
text, comment, startElement, …
are used. This causes problems when there are indeed nodes
named text or comment or startElement as a
node-specific handler are confused with the corresponding
general handler of the same name. Using <code>TRUE</code>
means that your list of handlers should have names that use
the ‘.’ prefix for these general element handlers.
This is the preferred way to write new code.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>xinclude</code>
</td>
<td>
<p>
a logical value indicating whether
to process nodes of the form <code>&lt;xi:include xmlns:xi="<a href="http://www.w3.org/2001/XInclude%22%3E" class="uri">http://www.w3.org/2001/XInclude"&gt;</a>;</code>
to insert content from other parts of (potentially different)
documents. <code>TRUE</code> means resolve the external references;
<code>FALSE</code> means leave the node as is.
Of course, one can process these nodes oneself after document has
been parse using handler functions or working on the DOM.
Please note that the syntax for inclusion using XPointer
is not the same as XPath and the results can be a little
unexpected and confusing. See the libxml2 documentation for more details.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>addFinalizer</code>
</td>
<td>
<p>
a logical value indicating whether the
default finalizer routine should be registered to
free the internal xmlDoc when R no longer has a reference to this
external pointer object. This is only relevant when
<code>useInternalNodes</code> is <code>TRUE</code>.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>error</code>
</td>
<td>
<p>
a function that is invoked when the XML parser reports
an error.
When an error is encountered, this is called with 7 arguments.
See <code>xmlStructuredStop</code> for information about these
</p>
<p>
If parsing completes and no document is generated, this function is
called again with only argument which is a character vector of
length 0. This gives the function an opportunity to report all the
errors and raise an exception rather than doing this when it sees
th first one.
</p>
<p>
This function can do what it likes with the information.
It can raise an R error or let parser continue and potentially
find further errors.
</p>
<p>
The default value of this argument supplies a function that
cumulates the errors
</p>
<p>
If this is <code>NULL</code>, the default error handler function in the
package <code>xmlStructuredStop</code> is invoked and this will
raise an error in R at that time in R.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>isHTML</code>
</td>
<td>
<p>
a logical value that allows this function to be used for parsing HTML documents.
This causes validation and processing of a DTD to be turned off.
This is currently experimental so that we can implement
<code>htmlParse</code> with this same function.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>options</code>
</td>
<td>
<p>
an integer value or vector of values that are combined
(OR’ed) together
to specify options for the XML parser. This is the same as the
<code>options</code> parameter for <code>xmlParseDoc</code>.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>parentFirst</code>
</td>
<td>
<p>
a logical value for use when we have handler
functions and are traversing the tree.
This controls whether we process
the node before processing its children, or process the children
before their parent node.
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
The <code>handlers</code> argument is used similarly
to those specified in xmlEventParse.
When an XML tag (element) is processed,
we look for a function in this collection
with the same name as the tag’s name.
If this is not found, we look for one named
<code>startElement</code>. If this is not found, we use the default
built in converter.
The same works for comments, entity references, cdata, processing instructions,
etc.
The default entries should be named
<code>comment</code>, <code>startElement</code>,
<code>externalEntity</code>,
<code>processingInstruction</code>,
<code>text</code>, <code>cdata</code> and <code>namespace</code>.
All but the last should take the XMLnode as their first argument.
In the future, other information may be passed via …,
for example, the depth in the tree, etc.
Specifically, the second argument will be the parent node into which they
are being added, but this is not currently implemented,
so should have a default value (<code>NULL</code>).
</p>
<p>
The <code>namespace</code> function is called with a single argument which
is an object of class <code>XMLNameSpace</code>. This contains
</p>
<dl>
<dt>
id
</dt>
<dd>
<p>
the namespace identifier as used to
qualify tag names;
</p>
</dd>
<dt>
uri
</dt>
<dd>
<p>
the value of the namespace identifier,
i.e. the URI
identifying the namespace.
</p>
</dd>
<dt>
local
</dt>
<dd>
<p>
a logical value indicating whether the definition
is local to the document being parsed.
</p>
</dd>
</dl>
<p>
One should note that the <code>namespace</code> handler is called before the
node in which the namespace definition occurs and its children are
processed. This is different than the other handlers which are called
after the child nodes have been processed.
</p>
<p>
Each of these functions can return arbitrary values that are then
entered into the tree in place of the default node passed to the
function as the first argument. This allows the caller to generate
the nodes of the resulting document tree exactly as they wish. If the
function returns <code>NULL</code>, the node is dropped from the resulting
tree. This is a convenient way to discard nodes having processed their
contents.
</p>
<h3>
Value
</h3>
<p>
By default ( when <code>useInternalNodes</code> is <code>FALSE</code>,
<code>getDTD</code> is <code>TRUE</code>, and no
handler functions are provided), the return value is, an object of
(S3) class <code>XMLDocument</code>.
This has two fields named <code>doc</code> and <code>dtd</code>
and are of class <code>DTDList</code> and <code>XMLDocumentContent</code> respectively.
</p>
<p>
If <code>getDTD</code> is <code>FALSE</code>, only the <code>doc</code> object is returned.
</p>
<p>
The <code>doc</code> object has three fields of its own:
<code>file</code>, <code>version</code> and <code>children</code>.
</p>
<table summary="R valueblock">
<tr valign="top">
<td>
<code><code>file</code></code>
</td>
<td>
<p>
The (expanded) name of the file containing the XML.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code><code>version</code></code>
</td>
<td>
<p>
A string identifying the version of XML used by the document.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code><code>children</code></code>
</td>
<td>
<p>
A list of the XML nodes at the top of the document.
Each of these is of class <code>XMLNode</code>.
These are made up of 4 fields.
</p>
<ul>
<li>
<p>
<code>name</code>The name of the element.
</p>
</li>
<li>
<p>
<code>attributes</code>For regular elements, a named list
of XML attributes converted from the
&lt;tag x=“1” y=“abc”&gt;
</p>
</li>
<li>
<p>
<code>children</code>List of sub-nodes.
</p>
</li>
<li>
<p>
<code>value</code>Used only for text entries.
</p>
</li>
</ul>
<p>
Some nodes specializations of <code>XMLNode</code>, such as
<code>XMLComment</code>, <code>XMLProcessingInstruction</code>,
<code>XMLEntityRef</code> are used.
</p>
<p>
If the value of the argument getDTD is TRUE and the document refers
to a DTD via a top-level DOCTYPE element, the DTD and its information
will be available in the <code>dtd</code> field. The second element is a
list containing the external and internal DTDs. Each of these
contains 2 lists - one for element definitions and another for entities. See
<code>parseDTD</code>.
</p>
<p>
If a list of functions is given via <code>handlers</code>,
this list is returned. Typically, these handler functions
share state via a closure and the resulting updated data structures
which contain the extracted and processed values from the XML
document can be retrieved via a function in this handler list.
</p>
<p>
If <code>asTree</code> is <code>TRUE</code>, then the converted tree is returned.
What form this takes depends on what the handler functions have
done to process the XML tree.
</p>
<p>
If <code>useInternalNodes</code> is <code>TRUE</code> and no handlers are
specified, an object of S3 class <code>XMLInternalDocument</code> is
returned. This can be used in much the same ways as an
<code>XMLDocument</code>, e.g. with <code>xmlRoot</code>,
<code>docName</code> and so on to traverse the tree.
It can also be used with XPath queries via <code>getNodeSet</code>,
<code>xpathApply</code> and <code>doc[“xpath-expression”]</code>.
</p>
<p>
If internal nodes are used and the internal tree returned directly,
all the nodes are returned as-is and no attempt to
trim white space, remove “empty” nodes (i.e. containing only white
space), etc. is done. This is potentially quite expensive and so is
not done generally, but should be done during the processing
of the nodes. When using XPath queries, such nodes are easily
identified and/or ignored and so do not cause any difficulties.
They do become an issue when dealing with a node’s chidren
directly and so one can use simple filtering techniques such as
<code> xmlChildren(node)[ ! xmlSApply(node, inherits, “XMLInternalTextNode”)]</code>
and even check the <code>xmlValue</code> to determine if it contains only
white space.
<code> xmlChildren(node)[ ! xmlSApply(node, function(x) inherit(x,
“XMLInternalTextNode”)] &amp;&amp; trim(xmlValue(x)) == "")</code>
</p>
</td>
</tr>
</table>
<h3>
Note
</h3>
<p>
Make sure that the necessary 3rd party libraries are available.
</p>
<h3>
Author(s)
</h3>
<p>
Duncan Temple Lang &lt;<a href="mailto:duncan@wald.ucdavis.edu%3E" class="email">duncan@wald.ucdavis.edu&gt;</a>
</p>
<h3>
References
</h3>
<p>
<a href="http://xmlsoft.org">http://xmlsoft.org</a>, <a href="http://www.w3.org/xml">http://www.w3.org/xml</a>
</p>
<h3>
See Also
</h3>
<p>
xmlEventParse,
<code>free</code> for releasing the memory when
an <code>XMLInternalDocument</code> object is returned.
</p>
<h3>
Examples
</h3>
<pre>
 fileName &lt;- system.file("exampleData", "test.xml", package="XML")
   # parse the document and return it in its standard format.

 xmlTreeParse(fileName)

   # parse the document, discarding comments.

 xmlTreeParse(fileName, handlers=list("comment"=function(x,...){NULL}), asTree = TRUE)

   # print the entities
 invisible(xmlTreeParse(fileName,
            handlers=list(entity=function(x) {
                                    cat("In entity",x$name, x$value,"\n")
                                    x}
                                  ), asTree = TRUE
                          )
          )

 # Parse some XML text.
 # Read the text from the file
 xmlText &lt;- paste(readLines(fileName), "\n", collapse="")

 print(xmlText)
 xmlTreeParse(xmlText, asText=TRUE)


    # with version 1.4.2 we can pass the contents of an XML
    # stream without pasting them.
 xmlTreeParse(readLines(fileName), asText=TRUE)


 # Read a MathML document and convert each node
 # so that the primary class is 
 #   &lt;name of tag&gt;MathML
 # so that we can use method  dispatching when processing
 # it rather than conditional statements on the tag name.
 # See plotMathML() in examples/.
 fileName &lt;- system.file("exampleData", "mathml.xml",package="XML")
m &lt;- xmlTreeParse(fileName, 
                  handlers=list(
                   startElement = function(node){
                   cname &lt;- paste(xmlName(node),"MathML", sep="",collapse="")
                   class(node) &lt;- c(cname, class(node)); 
                   node
                }))



  # In this example, we extract _just_ the names of the
  # variables in the mtcars.xml file. 
  # The names are the contents of the &lt;variable&gt;
  # tags. We discard all other tags by returning NULL
  # from the startElement handler.
  #
  # We cumulate the names of variables in a character
  # vector named `vars'.
  # We define this within a closure and define the 
  # variable function within that closure so that it
  # will be invoked when the parser encounters a &lt;variable&gt;
  # tag.
  # This is called with 2 arguments: the XMLNode object (containing
  # its children) and the list of attributes.
  # We get the variable name via call to xmlValue().

  # Note that we define the closure function in the call and then 
  # create an instance of it by calling it directly as
  #   (function() {...})()

  # Note that we can get the names by parsing
  # in the usual manner and the entire document and then executing
  # xmlSApply(xmlRoot(doc)[[1]], function(x) xmlValue(x[[1]]))
  # which is simpler but is more costly in terms of memory.
 fileName &lt;- system.file("exampleData", "mtcars.xml", package="XML")
 doc &lt;- xmlTreeParse(fileName,  handlers = (function() { 
                                 vars &lt;- character(0) ;
                                list(variable=function(x, attrs) { 
                                                vars &lt;&lt;- c(vars, xmlValue(x[[1]])); 
                                                NULL}, 
                                     startElement=function(x,attr){
                                                   NULL
                                                  }, 
                                     names = function() {
                                                 vars
                                             }
                                    )
                               })()
                     )

  # Here we just print the variable names to the console
  # with a special handler.
 doc &lt;- xmlTreeParse(fileName, handlers = list(
                                  variable=function(x, attrs) {
                                             print(xmlValue(x[[1]])); TRUE
                                           }), asTree=TRUE)


  # This should raise an error.
  try(xmlTreeParse(
            system.file("exampleData", "TestInvalid.xml", package="XML"),
            validate=TRUE))

## Not run: 
 # Parse an XML document directly from a URL.
 # Requires Internet access.
 xmlTreeParse("http://www.omegahat.net/Scripts/Data/mtcars.xml", asText=TRUE)

## End(Not run)

  counter = function() {
              counts = integer(0)
              list(startElement = function(node) {
                                     name = xmlName(node)
                                     if(name %in% names(counts))
                                          counts[name] &lt;&lt;- counts[name] + 1
                                     else
                                          counts[name] &lt;&lt;- 1
                                  },
                    counts = function() counts)
            }

   h = counter()
   xmlParse(system.file("exampleData", "mtcars.xml", package="XML"),  handlers = h)
   h$counts()



 f = system.file("examples", "index.html", package = "XML")
 htmlTreeParse(readLines(f), asText = TRUE)
 htmlTreeParse(readLines(f))

  # Same as 
 htmlTreeParse(paste(readLines(f), collapse = "\n"), asText = TRUE)


 getLinks = function() { 
       links = character() 
       list(a = function(node, ...) { 
                   links &lt;&lt;- c(links, xmlGetAttr(node, "href"))
                   node 
                }, 
            links = function()links)
     }

 h1 = getLinks()
 htmlTreeParse(system.file("examples", "index.html", package = "XML"),
               handlers = h1)
 h1$links()

 h2 = getLinks()
 htmlTreeParse(system.file("examples", "index.html", package = "XML"),
              handlers = h2, useInternalNodes = TRUE)
 all(h1$links() == h2$links())

  # Using flat trees
 tt = xmlHashTree()
 f = system.file("exampleData", "mtcars.xml", package="XML")
 xmlTreeParse(f, handlers = list(.startElement = tt[[".addNode"]]))
 xmlRoot(tt)



 doc = xmlTreeParse(f, useInternalNodes = TRUE)

 sapply(getNodeSet(doc, "//variable"), xmlValue)

 #free(doc) 


  # character set encoding for HTML
 f = system.file("exampleData", "9003.html", package = "XML")
   # we specify the encoding
 d = htmlTreeParse(f, encoding = "UTF-8")
   # get a different result if we do not specify any encoding
 d.no = htmlTreeParse(f)
   # document with its encoding in the HEAD of the document.
 d.self = htmlTreeParse(system.file("exampleData", "9003-en.html",package = "XML"))
   # XXX want to do a test here to see the similarities between d and
   # d.self and differences between d.no


  # include
 f = system.file("exampleData", "nodes1.xml", package = "XML")
 xmlRoot(xmlTreeParse(f, xinclude = FALSE))
 xmlRoot(xmlTreeParse(f, xinclude = TRUE))

 f = system.file("exampleData", "nodes2.xml", package = "XML")
 xmlRoot(xmlTreeParse(f, xinclude = TRUE))

  # Errors
  try(xmlTreeParse("&lt;doc&gt;&lt;a&gt; &amp; &lt; &lt;?pi &gt; &lt;/doc&gt;"))

    # catch the error by type.
 tryCatch(xmlTreeParse("&lt;doc&gt;&lt;a&gt; &amp; &lt; &lt;?pi &gt; &lt;/doc&gt;"),
                "XMLParserErrorList" = function(e) {
                     cat("Errors in XML document\n", e$message, "\n")
                                                    })

    #  terminate on first error            
  try(xmlTreeParse("&lt;doc&gt;&lt;a&gt; &amp; &lt; &lt;?pi &gt; &lt;/doc&gt;", error = NULL))

    #  see xmlErrorCumulator in the XML package 


  f = system.file("exampleData", "book.xml", package = "XML")
  doc.trim = xmlInternalTreeParse(f, trim = TRUE)
  doc = xmlInternalTreeParse(f, trim = FALSE)
  xmlSApply(xmlRoot(doc.trim), class)
      # note the additional XMLInternalTextNode objects
  xmlSApply(xmlRoot(doc), class)


  top = xmlRoot(doc)
  textNodes = xmlSApply(top, inherits, "XMLInternalTextNode")
  sapply(xmlChildren(top)[textNodes], xmlValue)


     # Storing nodes
   f = system.file("exampleData", "book.xml", package = "XML")
   titles = list()
   xmlTreeParse(f, handlers = list(title = function(x)
                                  titles[[length(titles) + 1]] &lt;&lt;- x))
   sapply(titles, xmlValue)
   rm(titles)
</pre>
<hr />
<div style="text-align: center;">
[Package <em>XML</em> version 3.99-0.5 ]
</div>
<p>We can now use the function <code>getURLContent()</code> to retrieve the source of a webpage, which is especially useful for retrieving pages for data processing (i.e. scraping). We will apply the function <code>htmlParse()</code> to obtain an R object.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="data-scraping-in-progress.html#cb23-1" aria-hidden="true" tabindex="-1"></a>fishbase <span class="ot">&lt;-</span> <span class="fu">htmlParse</span>(<span class="fu">getURLContent</span>(url1, <span class="at">followlocation=</span><span class="cn">TRUE</span>)) </span></code></pre></div>
<p>Below we can see a print screen of part of the object <em>fishbase</em>. <img src="../data/images/fishbase.png" alt="alt" /></p>
<p>In the next figure we can see another extract.
This printscreen of part of the object fishbase is related to the maximal length.<img src="../data/images/fishbase_maxle.png" alt="alt" /></p>
<p>Highlighted in <font color=red> red </font> we can see the opening and closing tags in the HTML extract, these tag block are used to identify points of interest in this example.
So we need to extract the <b>span/div</b> blocks.</p>
<p>In order to extract the information inside these two blocks, we are going to use the function <code>getNodeSet()</code> to find XML nodes that match a particular criterion. <b>Span</b> is used for a small chunk of HTML inside a line and <strong>div</strong> to group larger chunks of code. This will make finding and extracting information easier.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="data-scraping-in-progress.html#cb24-1" aria-hidden="true" tabindex="-1"></a>fishbase_div <span class="ot">&lt;-</span><span class="fu">getNodeSet</span>(fishbase, <span class="st">&quot;//div &quot;</span>) </span>
<span id="cb24-2"><a href="data-scraping-in-progress.html#cb24-2" aria-hidden="true" tabindex="-1"></a>fishbase_span <span class="ot">&lt;-</span> <span class="fu">getNodeSet</span>(fishbase, <span class="st">&quot;//span &quot;</span>) </span></code></pre></div>
<p>In the next two figures we can see the differences after executing the command <code>getNodeSet(fishbase, "//div ")</code>. A similar result is obtained for <code>getNodeSet(fishbase, "//span ")</code>.</p>
<p>Extract before the command <code>getNodeSet()</code>.
<img src="../data/images/before.png" /></p>
<p>Extract after the command <code>getNodeSet()</code>.
<img src="../data/images/after.png" /></p>
<p>Hence, <code>getNodeSet()</code> will identify all the sections for a given tag and separate them out into a list.</p>
<hr />
</div>
<div id="getting-a-numerical-value-from-fishbase" class="section level3" number="5.4.3">
<h3><span class="header-section-number">5.4.3</span> 3.4 Getting a numerical value from FishBase</h3>
<p>We now want to get the maximal length of the <em>Coregonus lavaretus</em>. Some types of XML nodes have no children nodes, but are leaf nodes and simply contain text. So the function <code>xmlValue()</code> provides access to their raw contents.</p>
<p>Now let us briefly discuss <em>regular expressions</em>. A <em>regular expression</em> is a pattern that describes a set of strings. So we will use <code>regexec()</code> to search for matches to argument pattern within each element of a character vector. In this case, we are going to look for the pattern “Max length,” because, after this pattern, we can read its value as shown in the next figure.</p>
<div class="figure">
<img src="../data/images/length.png" alt="" />
<p class="caption">Maximal length.</p>
</div>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="data-scraping-in-progress.html#cb25-1" aria-hidden="true" tabindex="-1"></a>fish_length <span class="ot">&lt;-</span> <span class="fu">xmlValue</span>(fishbase_span[[<span class="fu">which.max</span>(<span class="fu">sapply</span>(<span class="fu">lapply</span>(fishbase_span,xmlValue) </span>
<span id="cb25-2"><a href="data-scraping-in-progress.html#cb25-2" aria-hidden="true" tabindex="-1"></a>, <span class="cf">function</span>(x){<span class="fu">regexec</span>(<span class="at">pattern=</span><span class="st">&quot;Max length&quot;</span>, x)[[<span class="dv">1</span>]][<span class="dv">1</span>]}))]])</span></code></pre></div>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="data-scraping-in-progress.html#cb26-1" aria-hidden="true" tabindex="-1"></a>fish_length</span></code></pre></div>
<pre><code>## [1] &quot;\r\n\t\t\t\t\tMaturity: Lm27.1, range 40 - ? cm Max length : 73.0 cm TL male/unsexed; (Ref. 40637); max. published weight: 10.0 kg (Ref. 35388)\t\t\t\t&quot;</code></pre>
<p>’: Lm27.1, range 40 - ? cm Max length : 73.0 cm TL male/unsexed; (Ref. 40637); max. published weight: 10.0 kg (Ref. 35388)</p>
<p>We then use the function <code>substr()</code>, which you already encountered in previous chapters, to extract a part (the length we are looking for) of the character vector. We need to find the interval (section) we want to extract. With <code>regexec()</code> we are looking for the pattern <em>Max length</em>. To get the fish length we will extract the letters from position 13 (which is a 7) to position 16 (which is a 0). You can also count these positions from the image above starting from ‘M’ in Max length. Keep in mind that every blank space is also counted. Another way to do that is based on a trial and error basis.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="data-scraping-in-progress.html#cb28-1" aria-hidden="true" tabindex="-1"></a>max_length <span class="ot">&lt;-</span> <span class="fu">substr</span>(fish_length, <span class="fu">regexec</span>(<span class="at">pattern=</span><span class="st">&quot;Max length&quot;</span>, fish_length)[[<span class="dv">1</span>]][<span class="dv">1</span>]<span class="sc">+</span><span class="dv">13</span></span>
<span id="cb28-2"><a href="data-scraping-in-progress.html#cb28-2" aria-hidden="true" tabindex="-1"></a>, <span class="fu">regexec</span>(<span class="at">pattern=</span><span class="st">&quot;Max length&quot;</span>, fish_length)[[<span class="dv">1</span>]][<span class="dv">1</span>]<span class="sc">+</span><span class="dv">16</span>)</span>
<span id="cb28-3"><a href="data-scraping-in-progress.html#cb28-3" aria-hidden="true" tabindex="-1"></a>max_length</span></code></pre></div>
<pre><code>## [1] &quot;73.0&quot;</code></pre>
<p>‘73.0’</p>
<p>Now we should convert the value of the maximal length (which is a character) into a number with the function <code>as.double()</code>. We convert it into a double format in order to simplify things and make it machine readable. For example, if an integer value is followed by any character let’s say ‘R,’ we would be able to read that value without an error if it is in double format. It increases the flexibility in data reading.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="data-scraping-in-progress.html#cb30-1" aria-hidden="true" tabindex="-1"></a>max_length <span class="ot">&lt;-</span> <span class="fu">as.double</span>(max_length, <span class="at">base =</span> 0L)</span>
<span id="cb30-2"><a href="data-scraping-in-progress.html#cb30-2" aria-hidden="true" tabindex="-1"></a>max_length</span></code></pre></div>
<pre><code>## [1] 73</code></pre>
<p>73</p>
<p>We see the maximal length of the <em>Coregonus lavaretus</em> is 73 cm. One can now start to assemble/collect those numbers into “suitable” data containers or formats. We will put all the data into a dataframe in the later sections.</p>
<hr />
<div style="border: 2px black solid; border-radius: 7px; padding:10px">
<pre><code>&lt;b&gt;IUCN Red List&lt;/b&gt;&lt;br/&gt;</code></pre>
<p>Before we go on we would like to introduce the <b>IUCN</b> status of species. IUCN (International Union for Conservation of Nature’s) Red List of Threatened Species, also called <b>IUCN Red List</b> has evolved to become the world’s most comprehensive information source on the global extinction risk status of animal, fungus and plant species.</p>
<p>The IUCN Red List is a critical indicator of the health of the world’s biodiversity. Far more than a list of species and their status, it is a powerful tool to inform and catalyse action for biodiversity conservation and policy change, critical to protecting the natural resources we need to survive. It provides information about the range, population size, habitat and ecology, use and/or trade, threats, and conservation actions that will help inform necessary conservation decisions.</p>
<p>IUCN Red List is one of the most well-known objective assessment systems for classifying the status of plants, animals, and other organisms threatened with extinction. IUCN unveiled this assessment system in 1994. It contains explicit criteria and categories to classify the conservation status of individual species on the basis of their probability of extinction. After a species is evaluated by the IUCN, it is placed into one of eight categories based on its current conservation status as shown in the figure.</p>
<div class="figure">
<img src="../data/images/iucn.png" alt="" />
<p class="caption">IUCN status.</p>
</div>
</div>
<hr />
</div>
<div id="getting-a-block-of-text-value-from-fishbase" class="section level3" number="5.4.4">
<h3><span class="header-section-number">5.4.4</span> 3.5 Getting a block of text value from FishBase</h3>
<p>In this part, we are going to get the IUCN Status of <em>Coregonus lavaretus</em>. We are going to use the function <code>which()</code> to find the position of the elements we are looking for. We use <code>regexec()</code> to search for matches to the argument pattern within each element of a character vector. In this case, the pattern is IUCN. The pattern can be found, as for the maximal length, on the webpage from which we are getting the data.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="data-scraping-in-progress.html#cb33-1" aria-hidden="true" tabindex="-1"></a>w_IUCN  <span class="ot">&lt;-</span><span class="fu">which</span>(<span class="fu">sapply</span>(<span class="fu">lapply</span>(fishbase_div,xmlValue),<span class="cf">function</span>(x)</span>
<span id="cb33-2"><a href="data-scraping-in-progress.html#cb33-2" aria-hidden="true" tabindex="-1"></a>  {<span class="fu">regexec</span>(<span class="at">pattern=</span><span class="st">&quot;IUCN&quot;</span>, x)[[<span class="dv">1</span>]][<span class="dv">1</span>]})<span class="sc">&gt;</span><span class="dv">0</span>)</span></code></pre></div>
<p>Now if w_IUCN is empty, we set it as NA. Otherwise we use the function <code>xmlValue()</code> to get the value at the node.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="data-scraping-in-progress.html#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="fu">length</span>(w_IUCN)<span class="sc">==</span><span class="dv">0</span>){ </span>
<span id="cb34-2"><a href="data-scraping-in-progress.html#cb34-2" aria-hidden="true" tabindex="-1"></a>  IUCN_status<span class="ot">=</span><span class="st">&quot;NA&quot;</span></span>
<span id="cb34-3"><a href="data-scraping-in-progress.html#cb34-3" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb34-4"><a href="data-scraping-in-progress.html#cb34-4" aria-hidden="true" tabindex="-1"></a>  d1_IUCN  <span class="ot">&lt;-</span> <span class="fu">xmlValue</span>(fishbase_div[[w_IUCN[<span class="fu">length</span>(w_IUCN)]]])</span>
<span id="cb34-5"><a href="data-scraping-in-progress.html#cb34-5" aria-hidden="true" tabindex="-1"></a>} </span></code></pre></div>
<p>In the next we can see the output of <em>d1_IUCN</em>.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="data-scraping-in-progress.html#cb35-1" aria-hidden="true" tabindex="-1"></a>d1_IUCN </span></code></pre></div>
<pre><code>## [1] &quot;\r\n\t\t\t\t\r\n\t\t\t\t\tIUCN Red List Status   (Ref. 120744)\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\t  Vulnerable (VU) (D2); Date assessed: 01 January 2008\t\t\t\t\r\n\t\t\t\t&quot;</code></pre>
<p><span style="white-space:pre-wrap">’Red List Status (Ref. 120744) Vulnerable (VU) (D2); Date assessed: 01 January 2008</span></p>
<p>This all looks a little confusing and we only really need a tiny part, namely <em>VU</em>, of the above information. So we are going to use <code>unlist()</code> to produce a vector which contains all the atomic components that occurs in the pattern (the pattern <code>[[:alpha:]]+</code> is used to get the alphabetic characters) and <code>regmatches()</code> is used to extract or replace matched substrings from data obtained by <code>gregexpr()</code>. The function <code>gregexpr()</code>does the same thing as <code>regexec()</code>, except that its returned object is a list rather than a vector.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="data-scraping-in-progress.html#cb37-1" aria-hidden="true" tabindex="-1"></a>IUCN <span class="ot">&lt;-</span> <span class="fu">unlist</span>(<span class="fu">regmatches</span>(d1_IUCN,<span class="fu">gregexpr</span>(<span class="at">pattern=</span> <span class="st">&quot;[[:alpha:]]+)&quot;</span>,   d1_IUCN)))</span>
<span id="cb37-2"><a href="data-scraping-in-progress.html#cb37-2" aria-hidden="true" tabindex="-1"></a>IUCN</span></code></pre></div>
<pre><code>## [1] &quot;VU)&quot;</code></pre>
<p>‘VU)’</p>
<p>As you see to get to IUCN Status we need to remove the <em>“)”</em>. So we will use the function <code>str_replace()</code>. The <code>pattern="[[:punct:]]"</code> is used to remove punctuation.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="data-scraping-in-progress.html#cb39-1" aria-hidden="true" tabindex="-1"></a>IUCN_status <span class="ot">&lt;-</span> <span class="fu">str_replace</span>(IUCN,<span class="at">pattern=</span><span class="st">&quot;[[:punct:]]&quot;</span>,<span class="st">&quot;&quot;</span> )</span>
<span id="cb39-2"><a href="data-scraping-in-progress.html#cb39-2" aria-hidden="true" tabindex="-1"></a>IUCN_status</span></code></pre></div>
<pre><code>## [1] &quot;VU&quot;</code></pre>
<p>‘VU’</p>
<p>Hence the IUCN Status is <em>VU</em> (vulnerable) which is saved as a character. In this case, we will keep it as a character.</p>
<hr />
</div>
<div id="reading-a-table-from-a-website" class="section level3" number="5.4.5">
<h3><span class="header-section-number">5.4.5</span> 3.6 Reading a table from a website</h3>
<p>The next step is to read a table from a website. We are going to get information about the eggs of the <em>Coregonus lavaretus</em>.
We will use the function <code>getHTMLLinks()</code> to retrieve either the links within an HTML document or the collection of names of external files referenced in an HTML document.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="data-scraping-in-progress.html#cb41-1" aria-hidden="true" tabindex="-1"></a>link_list <span class="ot">&lt;-</span> <span class="fu">getHTMLLinks</span>(fishbase, <span class="at">externalOnly =</span> <span class="cn">TRUE</span>, <span class="at">xpQuery =</span> <span class="st">&quot;//a/@href&quot;</span></span>
<span id="cb41-2"><a href="data-scraping-in-progress.html#cb41-2" aria-hidden="true" tabindex="-1"></a>, <span class="at">baseURL =</span> <span class="fu">docName</span>(fishbase))</span></code></pre></div>
<p>In the next figure we can see an extract of <em>link_list</em>.</p>
<div class="figure">
<img src="../data/images/eggs.png" alt="" />
<p class="caption">link_list.</p>
</div>
<p>As highlighted, we need to look for the pattern <em>FishEggInfoSummary</em> and to do that we use the function <code>grep()</code> (similar to what we did before with <code>gregexpr()</code>).</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="data-scraping-in-progress.html#cb42-1" aria-hidden="true" tabindex="-1"></a>eggs_link <span class="ot">&lt;-</span> link_list[<span class="fu">grep</span>(<span class="st">&quot;FishEggInfoSummary&quot;</span>,link_list)]</span></code></pre></div>
<p><img src="../data/images/outputlink.png" /></p>
<p>The two extracts above look like they are the same object. To check if two objects are identical we use the logic operator <code>==</code>.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="data-scraping-in-progress.html#cb43-1" aria-hidden="true" tabindex="-1"></a>eggs_link[<span class="dv">1</span>]<span class="sc">==</span>eggs_link[<span class="dv">2</span>]</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>TRUE</p>
<p>Since, the output is TRUE. This indicates that the two objects are identical, now we can arbitrarily select the first or second object.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="data-scraping-in-progress.html#cb45-1" aria-hidden="true" tabindex="-1"></a>eggs_link <span class="ot">&lt;-</span>eggs_link[<span class="dv">1</span>]</span></code></pre></div>
<div style="background-color:rgba(0, 200, 0, 0.5);border-radius: 7px; padding:10px">
<pre><code>&lt;b&gt;Checkpoint&lt;/b&gt;&lt;br/&gt;
Call the variable &lt;i&gt;egg_link&lt;/i&gt;, you will notice the link begins with &#39;..&#39; (see above in the image). Your task is to remove these dots and so the link begins with &#39;/Reproduction/.. &#39;. </code></pre>
<p><em>Note:</em> make sure you run the code you will need it in the subsequent code.</p>
<p><em>Hint:</em> make use of function ‘str_replace().’</p>
</div>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="data-scraping-in-progress.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># your code</span></span></code></pre></div>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="data-scraping-in-progress.html#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Solution</span></span>
<span id="cb48-2"><a href="data-scraping-in-progress.html#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="data-scraping-in-progress.html#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="co"># replace &#39;..&#39; or here effectively remove &#39;..&#39;</span></span>
<span id="cb48-4"><a href="data-scraping-in-progress.html#cb48-4" aria-hidden="true" tabindex="-1"></a>eggs_link <span class="ot">&lt;-</span> <span class="fu">str_replace</span>(eggs_link, <span class="st">&quot;..&quot;</span>, <span class="st">&quot;&quot;</span> )</span>
<span id="cb48-5"><a href="data-scraping-in-progress.html#cb48-5" aria-hidden="true" tabindex="-1"></a>eggs_link</span></code></pre></div>
<pre><code>## [1] &quot;/Reproduction/FishEggInfoSummary.php?ID=232&amp;GenusName=Coregonus&amp;SpeciesName=lavaretus&amp;fc=76&amp;StockCode=246&quot;</code></pre>
<p>‘/Reproduction/FishEggInfoSummary.php?ID=232&amp;GenusName=Coregonus&amp;SpeciesName=lavaretus&amp;fc=76&amp;StockCode=246’</p>
<p>Similarly to what we did previously, we can get the content of the webpage with the function <code>getURLContent()</code>.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="data-scraping-in-progress.html#cb50-1" aria-hidden="true" tabindex="-1"></a>url_egg <span class="ot">&lt;-</span> <span class="fu">paste</span> (<span class="st">&quot;http://www.fishbase.org/&quot;</span>,eggs_link,<span class="at">sep=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb50-2"><a href="data-scraping-in-progress.html#cb50-2" aria-hidden="true" tabindex="-1"></a>egg_content <span class="ot">&lt;-</span> <span class="fu">getURLContent</span>(url_egg, <span class="at">followlocation=</span><span class="cn">TRUE</span>, <span class="at">.encoding=</span><span class="st">&quot;CE_UTF8&quot;</span>)</span></code></pre></div>
<p>In the next figure we can see an extract of <em>egg_content</em>.</p>
<div class="figure">
<img src="../data/images/extract_tt.png" alt="" />
<p class="caption">Extract of egg_content.</p>
</div>
<p>We will use <code>readHTMLTable()</code> to read in the table in the document.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="data-scraping-in-progress.html#cb51-1" aria-hidden="true" tabindex="-1"></a>egg_table <span class="ot">&lt;-</span> <span class="fu">readHTMLTable</span>(egg_content,<span class="at">header=</span><span class="cn">TRUE</span>,<span class="at">colClasses=</span><span class="cn">NULL</span>,<span class="at">skip.rows=</span><span class="fu">integer</span>(),</span>
<span id="cb51-2"><a href="data-scraping-in-progress.html#cb51-2" aria-hidden="true" tabindex="-1"></a>                       <span class="at">stringsAsFactors=</span><span class="cn">FALSE</span>,<span class="at">trim=</span><span class="cn">TRUE</span>,<span class="at">elFun=</span>xmlValue,</span>
<span id="cb51-3"><a href="data-scraping-in-progress.html#cb51-3" aria-hidden="true" tabindex="-1"></a>                       <span class="at">as.data.frame=</span><span class="cn">TRUE</span>,<span class="at">which=</span><span class="fu">integer</span>())[[<span class="dv">1</span>]]</span>
<span id="cb51-4"><a href="data-scraping-in-progress.html#cb51-4" aria-hidden="true" tabindex="-1"></a>egg_table</span></code></pre></div>
<pre><code>##               Main Ref.       
## 1  Place of Development       
## 2          Shape of Egg       
## 3            Attributes       
## 4         Color of Eggs       
## 5  Color of Oil Globule       
## 6 Additional Characters       
## 7    Get Information on Scirus</code></pre>
<table>
<caption>
A data.frame: 7 × 2
</caption>
<thead>
<tr>
<th scope="col">
Main Ref.
</th>
<th scope="col">
</th>
</tr>
<tr>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Place of Development
</td>
<td>
</td>
</tr>
<tr>
<td>
Shape of Egg
</td>
<td>
</td>
</tr>
<tr>
<td>
Attributes
</td>
<td>
</td>
</tr>
<tr>
<td>
Color of Eggs
</td>
<td>
</td>
</tr>
<tr>
<td>
Color of Oil Globule
</td>
<td>
</td>
</tr>
<tr>
<td>
Additional Characters
</td>
<td>
</td>
</tr>
<tr>
<td>
Get Information on
</td>
<td>
Scirus
</td>
</tr>
</tbody>
</table>
<p>Now we can extract information from the table. By using the function <code>which()</code> to find the information we are looking for. As we are looking for the shape of the egg, we will pass this value.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="data-scraping-in-progress.html#cb53-1" aria-hidden="true" tabindex="-1"></a>egg_shape <span class="ot">=</span> egg_table[<span class="fu">which</span>(egg_table[,<span class="dv">1</span>] <span class="sc">==</span> <span class="st">&quot;Shape of Egg&quot;</span>),<span class="dv">2</span>] <span class="co"># Shape of Egg</span></span>
<span id="cb53-2"><a href="data-scraping-in-progress.html#cb53-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-3"><a href="data-scraping-in-progress.html#cb53-3" aria-hidden="true" tabindex="-1"></a>egg_shape</span></code></pre></div>
<pre><code>## [1] &quot;&quot;</code></pre>
<p>’’</p>
<p>In case there is no information about a feature (hence the character is empty). We set the feature as NA.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="data-scraping-in-progress.html#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(egg_shape <span class="sc">==</span> <span class="st">&quot;&quot;</span>) {egg_shape <span class="ot">=</span> <span class="st">&quot;NA&quot;</span>}</span></code></pre></div>
<p>By calling the variable <em>egg_shape</em> again we see NA as output which indicates that the field that provides the data about the shape of an egg is empty.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="data-scraping-in-progress.html#cb56-1" aria-hidden="true" tabindex="-1"></a>egg_shape</span></code></pre></div>
<pre><code>## [1] &quot;NA&quot;</code></pre>
<p>‘NA’</p>
<p>We have no informations about the shape of the eggs of the <i>Coregonus lavaretus</i>.</p>
<p>Now we can put all the information into a data structure for the <b>Coregonus lavaretus</b>. In order to do that we will use the function <code>tibble()</code>.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="data-scraping-in-progress.html#cb58-1" aria-hidden="true" tabindex="-1"></a>data_species <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="st">&quot;Coregonus-lavaretus&quot;</span>, max_length, IUCN_status, egg_shape)</span>
<span id="cb58-2"><a href="data-scraping-in-progress.html#cb58-2" aria-hidden="true" tabindex="-1"></a>data_species</span></code></pre></div>
<pre><code>## # A tibble: 1 x 4
##   `&quot;Coregonus-lavaretus&quot;` max_length IUCN_status egg_shape
##   &lt;chr&gt;                        &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;    
## 1 Coregonus-lavaretus             73 VU          NA</code></pre>
<table>
<caption>
A tibble: 1 × 4
</caption>
<thead>
<tr>
<th scope="col">
“Coregonus-lavaretus”
</th>
<th scope="col">
max_length
</th>
<th scope="col">
IUCN_status
</th>
<th scope="col">
egg_shape
</th>
</tr>
<tr>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;dbl&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Coregonus-lavaretus
</td>
<td>
73
</td>
<td>
VU
</td>
<td>
NA
</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="data-scraping-in-progress.html#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(data_species)[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="st">&quot;Species&quot;</span></span>
<span id="cb60-2"><a href="data-scraping-in-progress.html#cb60-2" aria-hidden="true" tabindex="-1"></a>data_species</span></code></pre></div>
<pre><code>## # A tibble: 1 x 4
##   Species             max_length IUCN_status egg_shape
##   &lt;chr&gt;                    &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;    
## 1 Coregonus-lavaretus         73 VU          NA</code></pre>
<table>
<caption>
A tibble: 1 × 4
</caption>
<thead>
<tr>
<th scope="col">
Species
</th>
<th scope="col">
max_length
</th>
<th scope="col">
IUCN_status
</th>
<th scope="col">
egg_shape
</th>
</tr>
<tr>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;dbl&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Coregonus-lavaretus
</td>
<td>
73
</td>
<td>
VU
</td>
<td>
NA
</td>
</tr>
</tbody>
</table>
<p>In this way, we can now fetch the data about other species by repeating the same process and adding it to our <em>data_species</em> tibble.</p>
<div style="background-color:rgba(0, 200, 0, 0.5);border-radius: 7px; padding:10px">
<pre><code>&lt;b&gt;Checkpoint&lt;/b&gt;&lt;br/&gt;</code></pre>
<p>Now your task is to create a new variable <em>‘egg_color’</em> and fetch its data and add it to the table (follow the same process used for ‘egg_shape’).</p>
</div>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="data-scraping-in-progress.html#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># your code </span></span></code></pre></div>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="data-scraping-in-progress.html#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Solution</span></span>
<span id="cb64-2"><a href="data-scraping-in-progress.html#cb64-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-3"><a href="data-scraping-in-progress.html#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="co"># extract the info</span></span>
<span id="cb64-4"><a href="data-scraping-in-progress.html#cb64-4" aria-hidden="true" tabindex="-1"></a>egg_color <span class="ot">=</span> egg_table[<span class="fu">which</span>(egg_table[,<span class="dv">1</span>] <span class="sc">==</span> <span class="st">&quot;Color of Eggs&quot;</span>),<span class="dv">2</span>]</span>
<span id="cb64-5"><a href="data-scraping-in-progress.html#cb64-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-6"><a href="data-scraping-in-progress.html#cb64-6" aria-hidden="true" tabindex="-1"></a><span class="co"># set no information to NA</span></span>
<span id="cb64-7"><a href="data-scraping-in-progress.html#cb64-7" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(egg_color <span class="sc">==</span> <span class="st">&quot;&quot;</span>) {egg_color <span class="ot">=</span> <span class="st">&quot;NA&quot;</span>}</span>
<span id="cb64-8"><a href="data-scraping-in-progress.html#cb64-8" aria-hidden="true" tabindex="-1"></a>data_species <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="st">&quot;Coregonus-lavaretus&quot;</span>, max_length, IUCN_status, egg_shape, egg_color)</span>
<span id="cb64-9"><a href="data-scraping-in-progress.html#cb64-9" aria-hidden="true" tabindex="-1"></a>data_species</span></code></pre></div>
<pre><code>## # A tibble: 1 x 5
##   `&quot;Coregonus-lavaretus&quot;` max_length IUCN_status egg_shape egg_color
##   &lt;chr&gt;                        &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;    
## 1 Coregonus-lavaretus             73 VU          NA        NA</code></pre>
<table>
<caption>
A tibble: 1 × 5
</caption>
<thead>
<tr>
<th scope="col">
“Coregonus-lavaretus”
</th>
<th scope="col">
max_length
</th>
<th scope="col">
IUCN_status
</th>
<th scope="col">
egg_shape
</th>
<th scope="col">
egg_color
</th>
</tr>
<tr>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;dbl&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Coregonus-lavaretus
</td>
<td>
73
</td>
<td>
VU
</td>
<td>
NA
</td>
<td>
NA
</td>
</tr>
</tbody>
</table>
<hr />
</div>
<div id="r-interface-to-fishbase" class="section level3" number="5.4.6">
<h3><span class="header-section-number">5.4.6</span> 3.7 R interface to FishBase</h3>
<p>In this subsection, we want to get data using an API. We use the R package <code>rfishbase</code> to get data from <a href="https://www.fishbase.de" class="uri">https://www.fishbase.de</a>. The package <code>rfishbase</code> makes it relatively easy to look up for information on the most well-known fish species. As we saw in the previous sections, web scraping can be tedious. The <code>rfishbase</code> package simplifies the data extraction process but also has some limits as we will see later in the section.</p>
<p>Now we can get information on <em>Coregonus lavaretus</em> with this new package.</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="data-scraping-in-progress.html#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressWarnings</span>(<span class="fu">suppressMessages</span>(</span>
<span id="cb66-2"><a href="data-scraping-in-progress.html#cb66-2" aria-hidden="true" tabindex="-1"></a>data_CL<span class="ot">&lt;-</span> <span class="fu">species</span>(<span class="st">&quot;Coregonus lavaretus&quot;</span>) </span>
<span id="cb66-3"><a href="data-scraping-in-progress.html#cb66-3" aria-hidden="true" tabindex="-1"></a>))  </span>
<span id="cb66-4"><a href="data-scraping-in-progress.html#cb66-4" aria-hidden="true" tabindex="-1"></a>data_CL</span></code></pre></div>
<pre><code>## # A tibble: 1 x 101
##   SpecCode Species Genus SpeciesRefNo Author FBname PicPreferredName
##      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;           
## 1      232 Corego… Core…         5204 (Linn… Europ… Colav_u4.jpg    
## # … with 94 more variables: PicPreferredNameM &lt;chr&gt;, PicPreferredNameF &lt;chr&gt;,
## #   PicPreferredNameJ &lt;chr&gt;, FamCode &lt;dbl&gt;, Subfamily &lt;chr&gt;, GenCode &lt;dbl&gt;,
## #   SubGenCode &lt;dbl&gt;, BodyShapeI &lt;chr&gt;, Source &lt;chr&gt;, AuthorRef &lt;int&gt;,
## #   Remark &lt;chr&gt;, TaxIssue &lt;dbl&gt;, Fresh &lt;dbl&gt;, Brack &lt;dbl&gt;, Saltwater &lt;dbl&gt;,
## #   DemersPelag &lt;chr&gt;, Amphibious &lt;int&gt;, AmphibiousRef &lt;int&gt;, AnaCat &lt;chr&gt;,
## #   MigratRef &lt;dbl&gt;, DepthRangeShallow &lt;dbl&gt;, DepthRangeDeep &lt;dbl&gt;,
## #   DepthRangeRef &lt;dbl&gt;, DepthRangeComShallow &lt;dbl&gt;, DepthRangeComDeep &lt;dbl&gt;,
## #   DepthComRef &lt;dbl&gt;, LongevityWild &lt;dbl&gt;, LongevityWildRef &lt;dbl&gt;,
## #   LongevityCaptive &lt;dbl&gt;, LongevityCapRef &lt;dbl&gt;, Vulnerability &lt;dbl&gt;,
## #   Length &lt;dbl&gt;, LTypeMaxM &lt;chr&gt;, LengthFemale &lt;dbl&gt;, LTypeMaxF &lt;chr&gt;,
## #   MaxLengthRef &lt;dbl&gt;, CommonLength &lt;dbl&gt;, LTypeComM &lt;chr&gt;,
## #   CommonLengthF &lt;dbl&gt;, LTypeComF &lt;chr&gt;, CommonLengthRef &lt;dbl&gt;, Weight &lt;dbl&gt;,
## #   WeightFemale &lt;dbl&gt;, MaxWeightRef &lt;dbl&gt;, Pic &lt;chr&gt;, PictureFemale &lt;chr&gt;,
## #   LarvaPic &lt;chr&gt;, EggPic &lt;chr&gt;, ImportanceRef &lt;dbl&gt;, Importance &lt;chr&gt;,
## #   PriceCateg &lt;chr&gt;, PriceReliability &lt;chr&gt;, Remarks7 &lt;chr&gt;,
## #   LandingStatistics &lt;chr&gt;, Landings &lt;chr&gt;, MainCatchingMethod &lt;chr&gt;,
## #   II &lt;chr&gt;, MSeines &lt;dbl&gt;, MGillnets &lt;dbl&gt;, MCastnets &lt;dbl&gt;, MTraps &lt;dbl&gt;,
## #   MSpears &lt;dbl&gt;, MTrawls &lt;dbl&gt;, MDredges &lt;dbl&gt;, MLiftnets &lt;dbl&gt;,
## #   MHooksLines &lt;dbl&gt;, MOther &lt;dbl&gt;, UsedforAquaculture &lt;chr&gt;, LifeCycle &lt;chr&gt;,
## #   AquacultureRef &lt;dbl&gt;, UsedasBait &lt;chr&gt;, BaitRef &lt;dbl&gt;, Aquarium &lt;chr&gt;,
## #   AquariumFishII &lt;chr&gt;, AquariumRef &lt;dbl&gt;, GameFish &lt;dbl&gt;, GameRef &lt;dbl&gt;,
## #   Dangerous &lt;chr&gt;, DangerousRef &lt;dbl&gt;, Electrogenic &lt;chr&gt;, ElectroRef &lt;dbl&gt;,
## #   Complete &lt;int&gt;, GoogleImage &lt;dbl&gt;, Comments &lt;chr&gt;, Profile &lt;chr&gt;,
## #   PD50 &lt;dbl&gt;, Emblematic &lt;dbl&gt;, Entered &lt;dbl&gt;, DateEntered &lt;dbl&gt;,
## #   Modified &lt;dbl&gt;, DateModified &lt;dbl&gt;, Expert &lt;dbl&gt;, DateChecked &lt;dbl&gt;,
## #   TS &lt;int&gt;</code></pre>
<table>
<caption>
A tibble: 1 × 100
</caption>
<thead>
<tr>
<th scope="col">
SpecCode
</th>
<th scope="col">
Species
</th>
<th scope="col">
SpeciesRefNo
</th>
<th scope="col">
Author
</th>
<th scope="col">
FBname
</th>
<th scope="col">
PicPreferredName
</th>
<th scope="col">
PicPreferredNameM
</th>
<th scope="col">
PicPreferredNameF
</th>
<th scope="col">
PicPreferredNameJ
</th>
<th scope="col">
FamCode
</th>
<th scope="col">
⋯
</th>
<th scope="col">
Profile
</th>
<th scope="col">
PD50
</th>
<th scope="col">
Emblematic
</th>
<th scope="col">
Entered
</th>
<th scope="col">
DateEntered
</th>
<th scope="col">
Modified
</th>
<th scope="col">
DateModified
</th>
<th scope="col">
Expert
</th>
<th scope="col">
DateChecked
</th>
<th scope="col">
TS
</th>
</tr>
<tr>
<th scope="col">
&lt;dbl&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;dbl&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;dbl&gt;
</th>
<th scope="col">
⋯
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;dbl&gt;
</th>
<th scope="col">
&lt;dbl&gt;
</th>
<th scope="col">
&lt;dbl&gt;
</th>
<th scope="col">
&lt;dttm&gt;
</th>
<th scope="col">
&lt;dbl&gt;
</th>
<th scope="col">
&lt;dttm&gt;
</th>
<th scope="col">
&lt;dbl&gt;
</th>
<th scope="col">
&lt;dttm&gt;
</th>
<th scope="col">
&lt;lgl&gt;
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
232
</td>
<td>
Coregonus lavaretus
</td>
<td>
5204
</td>
<td>
(Linnaeus, 1758)
</td>
<td>
European whitefish
</td>
<td>
Colav_u4.jpg
</td>
<td>
NA
</td>
<td>
NA
</td>
<td>
NA
</td>
<td>
76
</td>
<td>
⋯
</td>
<td>
NA
</td>
<td>
0.5
</td>
<td>
0
</td>
<td>
2
</td>
<td>
1990-10-17
</td>
<td>
393
</td>
<td>
2017-03-06
</td>
<td>
1
</td>
<td>
1994-03-08
</td>
<td>
NA
</td>
</tr>
</tbody>
</table>
<p>We will start by getting the maximal length of the species. We’ll use the function <code>species()</code> to do this. In order to do that we look for the column <em>‘Length’</em> in the data.</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="data-scraping-in-progress.html#cb68-1" aria-hidden="true" tabindex="-1"></a>length_max_CL <span class="ot">&lt;-</span> <span class="fu">species</span>(<span class="st">&quot;Coregonus lavaretus&quot;</span>, <span class="at">fields=</span><span class="fu">c</span>(<span class="st">&quot;Length&quot;</span>))</span>
<span id="cb68-2"><a href="data-scraping-in-progress.html#cb68-2" aria-hidden="true" tabindex="-1"></a>length_max_CL <span class="ot">&lt;-</span> length_max_CL<span class="sc">$</span>Length</span>
<span id="cb68-3"><a href="data-scraping-in-progress.html#cb68-3" aria-hidden="true" tabindex="-1"></a>length_max_CL</span></code></pre></div>
<pre><code>## [1] 73</code></pre>
<p>73</p>
<p>As you might recall, this is the same value we got in section 3.4.</p>
<p>In the next step we are interested to get the information about the diet of <em>Coregonus lavaretus</em>. To get the diet information, we will use the function <code>diet_items()</code>. The function <code>diet_items()</code> allows us to access the table on the food items of the chosen species.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="data-scraping-in-progress.html#cb70-1" aria-hidden="true" tabindex="-1"></a>food <span class="ot">&lt;-</span> <span class="fu">diet_items</span>(<span class="st">&quot;Coregonus lavaretus&quot;</span>)</span>
<span id="cb70-2"><a href="data-scraping-in-progress.html#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(food)</span></code></pre></div>
<pre><code>## # Source:   lazy query [?? x 15]
## # Database: sqlite 3.34.1 [/Users/benjaminstocker/Library/Application
## #   Support/org.R-project.R/R/rfishbase/database/sqlite.sqlite]
##   autoctr DietCode FoodI FoodII FoodIII Stage DietPercent ItemName Comment
##     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;  
## 1  122522        1 zoob… mollu… bivalv… n.a.…        1    gastrop… 0.8% b…
## 2  101628        1 nekt… finfi… bony f… juv.…       18.1  Trisopt… 1% &lt;i&gt;…
## 3  107359        1 zoob… benth… lobste… juv.…       12.6  Galathe… Galath…
## 4  119985        1 zoob… worms  polych… juv.…        2.30 polycha… &lt;NA&gt;   
## 5  116667        1 zoob… benth… shrimp… juv.…        5    Pandali… Pandal…
## 6  112452        1 zoob… benth… shrimp… juv.…        5.30 Macropi… 0.5% &lt;…
## # … with 6 more variables: DietSpeccode &lt;dbl&gt;, DietSpeccodeSLB &lt;int&gt;,
## #   AlphaCode &lt;chr&gt;, PreyTroph &lt;dbl&gt;, PreySeTroph &lt;dbl&gt;, PreyRemark &lt;int&gt;</code></pre>
<table>
<caption>
A tibble: 6 × 15
</caption>
<thead>
<tr>
<th scope="col">
autoctr
</th>
<th scope="col">
DietCode
</th>
<th scope="col">
FoodI
</th>
<th scope="col">
FoodII
</th>
<th scope="col">
FoodIII
</th>
<th scope="col">
Stage
</th>
<th scope="col">
DietPercent
</th>
<th scope="col">
ItemName
</th>
<th scope="col">
Comment
</th>
<th scope="col">
DietSpeccode
</th>
<th scope="col">
DietSpeccodeSLB
</th>
<th scope="col">
AlphaCode
</th>
<th scope="col">
PreyTroph
</th>
<th scope="col">
PreySeTroph
</th>
<th scope="col">
PreyRemark
</th>
</tr>
<tr>
<th scope="col">
&lt;dbl&gt;
</th>
<th scope="col">
&lt;dbl&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;dbl&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;dbl&gt;
</th>
<th scope="col">
&lt;lgl&gt;
</th>
<th scope="col">
&lt;chr&gt;
</th>
<th scope="col">
&lt;dbl&gt;
</th>
<th scope="col">
&lt;dbl&gt;
</th>
<th scope="col">
&lt;lgl&gt;
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
122522
</td>
<td>
1
</td>
<td>
zoobenthos
</td>
<td>
mollusks
</td>
<td>
bivalves
</td>
<td>
n.a./others
</td>
<td>
1.0
</td>
<td>
gastropods
</td>
<td>
0.8% bivalves/gastropods incl. 0.1% euphausiids, 0.1% unid. organisms
</td>
<td>
NA
</td>
<td>
NA
</td>
<td>
GAS
</td>
<td>
NA
</td>
<td>
NA
</td>
<td>
NA
</td>
</tr>
<tr>
<td>
101628
</td>
<td>
1
</td>
<td>
<span style="white-space:pre-wrap">nekton </span>
</td>
<td>
<span style="white-space:pre-wrap">finfish </span>
</td>
<td>
<span style="white-space:pre-wrap">bony fish </span>
</td>
<td>
juv./adults
</td>
<td>
18.1
</td>
<td>
Trisopterus minutus
</td>
<td>
1% &lt;i&gt;Rhinonemus minutus&lt;/i&gt;,4.1% &lt;i&gt;Trisopterus minutus&lt;/i&gt;, 0.2% Gobiidae, 3.3% &lt;i&gt;Trisopterus esmarkii&lt;/i&gt;,0.8% &lt;i&gt;Lumpenus&lt;/i&gt;,1.3% &lt;i&gt;Scyliorhinus canicula&lt;/i&gt;,7.4% unid. Fish
</td>
<td>
481
</td>
<td>
NA
</td>
<td>
POD
</td>
<td>
NA
</td>
<td>
NA
</td>
<td>
NA
</td>
</tr>
<tr>
<td>
107359
</td>
<td>
1
</td>
<td>
zoobenthos
</td>
<td>
benth. crust.
</td>
<td>
lobsters
</td>
<td>
juv./adults
</td>
<td>
12.6
</td>
<td>
Galatheidae
</td>
<td>
Galatheidae
</td>
<td>
NA
</td>
<td>
NA
</td>
<td>
LOQ
</td>
<td>
NA
</td>
<td>
NA
</td>
<td>
NA
</td>
</tr>
<tr>
<td>
119985
</td>
<td>
1
</td>
<td>
zoobenthos
</td>
<td>
worms
</td>
<td>
polychaetes
</td>
<td>
juv./adults
</td>
<td>
2.3
</td>
<td>
polychaetes
</td>
<td>
NA
</td>
<td>
NA
</td>
<td>
NA
</td>
<td>
WOR
</td>
<td>
NA
</td>
<td>
NA
</td>
<td>
NA
</td>
</tr>
<tr>
<td>
116667
</td>
<td>
1
</td>
<td>
zoobenthos
</td>
<td>
benth. crust.
</td>
<td>
shrimps/prawns
</td>
<td>
juv./adults
</td>
<td>
5.0
</td>
<td>
Pandalidae
</td>
<td>
Pandalidae
</td>
<td>
NA
</td>
<td>
NA
</td>
<td>
PDZ
</td>
<td>
NA
</td>
<td>
NA
</td>
<td>
NA
</td>
</tr>
<tr>
<td>
112452
</td>
<td>
1
</td>
<td>
zoobenthos
</td>
<td>
benth. crust.
</td>
<td>
shrimps/prawns
</td>
<td>
juv./adults
</td>
<td>
5.3
</td>
<td>
<span style="white-space:pre-wrap">Macropipus </span>
</td>
<td>
<span style="white-space:pre-wrap">0.5% &lt;i&gt;Crangon&lt;/i&gt;, 0.5% &lt;i&gt;Processa&lt;/i&gt;, 2.3% &lt;i&gt;Macropipus&lt;/i&gt;, 0.7% Majidae, 0.1% Paguridae </span>
</td>
<td>
NA
</td>
<td>
NA
</td>
<td>
NA
</td>
<td>
NA
</td>
<td>
NA
</td>
<td>
NA
</td>
</tr>
</tbody>
</table>
<p>From the table food we can exract the column named <em>‘FoodII’</em>. As you already know, the simplest way to extract a column from a table is to use the <code>$</code> operator between the table name and column name respectively.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="data-scraping-in-progress.html#cb72-1" aria-hidden="true" tabindex="-1"></a>food_II <span class="ot">&lt;-</span> food<span class="sc">$</span>FoodII</span></code></pre></div>
<p>We can now extract the first and second elements of the column <em>‘food_II’</em> to get a short overview of the diet of <em>Coregonus lavaretus</em>.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="data-scraping-in-progress.html#cb73-1" aria-hidden="true" tabindex="-1"></a>food_II[<span class="dv">1</span>]</span></code></pre></div>
<pre><code>## NULL</code></pre>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="data-scraping-in-progress.html#cb75-1" aria-hidden="true" tabindex="-1"></a>food_II[<span class="dv">2</span>]</span></code></pre></div>
<pre><code>## NULL</code></pre>
<p>‘mollusks’</p>
<p>‘finfish’</p>
<p>As an output we get ‘mollusks’and ’finfish.’</p>
<p>In the same way, can get the information about the predators.</p>
<div style="background-color:rgba(0, 200, 0, 0.5);border-radius: 7px; padding:10px">
<pre><code>&lt;b&gt;Checkpoint&lt;/b&gt;&lt;br/&gt;
 Now your next task is to get the information about predators. In order to obtain the information you can simply use the function &#39;predators()&#39;. </code></pre>
</div>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="data-scraping-in-progress.html#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># your code</span></span></code></pre></div>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="data-scraping-in-progress.html#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Solution</span></span>
<span id="cb79-2"><a href="data-scraping-in-progress.html#cb79-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-3"><a href="data-scraping-in-progress.html#cb79-3" aria-hidden="true" tabindex="-1"></a><span class="co"># use function &#39;predators()&#39; for Coregonus lavaretus</span></span>
<span id="cb79-4"><a href="data-scraping-in-progress.html#cb79-4" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predators</span>(<span class="st">&quot;Coregonus lavaretus&quot;</span>)</span>
<span id="cb79-5"><a href="data-scraping-in-progress.html#cb79-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-6"><a href="data-scraping-in-progress.html#cb79-6" aria-hidden="true" tabindex="-1"></a><span class="co"># you can look at the column &#39;PredatorName&#39; to get the names of the predators</span></span>
<span id="cb79-7"><a href="data-scraping-in-progress.html#cb79-7" aria-hidden="true" tabindex="-1"></a>pred_name <span class="ot">&lt;-</span> pred<span class="sc">$</span>PredatorName</span>
<span id="cb79-8"><a href="data-scraping-in-progress.html#cb79-8" aria-hidden="true" tabindex="-1"></a>pred_name</span></code></pre></div>
<pre><code>## [1] &quot;Coregonus peled&quot;      &quot;Esox lucius&quot;          &quot;Salmo trutta trutta&quot; 
## [4] &quot;Sander lucioperca&quot;    &quot;Phryganea sp.&quot;        &quot;Coregonus lavaretus&quot; 
## [7] &quot;Lampetra fluviatilis&quot;</code></pre>
<style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class="list-inline">
<li>
‘Coregonus peled’
</li>
<li>
‘Esox lucius’
</li>
<li>
‘Sander lucioperca’
</li>
<li>
‘Lampetra fluviatilis’
</li>
<li>
‘Salmo trutta trutta’
</li>
<li>
‘Coregonus lavaretus’
</li>
<li>
‘Phryganea sp.’
</li>
</ol>
<p>So we obtained list of predators of <em>Coregonus lavaretus</em>.
For other functions in the R package <code>rfishbase</code> check <a href="https://cran.r-project.org/web/packages/rfishbase/rfishbase.pdf" class="uri">https://cran.r-project.org/web/packages/rfishbase/rfishbase.pdf</a>.</p>
<p><strong>Limits of API:</strong> One of the major limitations of an API is that we can only use already implemented functions. For example, in our case, we cannot get the IUCN Status of a given species. In order to obtain the IUCN Status we must use another API, namely the package <code>rredlist</code>. But to have access to the <em>rredlist</em> API we need a key (a key serves as an authentication barrier to have access to the API and often comes as a paid service). Hence, we will not do that in this exercise.</p>
<hr />
</div>
<div id="summary" class="section level3" number="5.4.7">
<h3><span class="header-section-number">5.4.7</span> 3.8 Summary</h3>
<div style="border: 2px black solid; border-radius: 7px; padding:10px">
<ul>
<li><p>In this third section we learned how to extract data from a website.</p></li>
<li><p>We saw that this can be done either with web scraping or using APIs.</p></li>
<li><p>We saw that web scraping can be tedious, but on the other hand we also saw some limitations of APIs.</p></li>
</ul>
</div>
<p>Next, we look at another case study on species richness and red list species proportions.</p>
<hr />
</div>
</div>
<div id="case-study-species-richness-and-red-list-species-proportions" class="section level2" number="5.5">
<h2><span class="header-section-number">5.5</span> 4. Case Study: Species richness and Red List species proportions</h2>
<p>To proceed with the case study we need to prepare our dataset. First, we need to get a list of species for the dataset. In this subsection we will see how to get all the species in a given family.</p>
<hr />
<div id="getting-all-the-species-in-a-family" class="section level3" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> 4.1 Getting all the species in a family</h3>
<p>In this section, we want to get all the species of the family of <strong>Salmonidae</strong>. As before for flexibility reasons, we will create an object <em>y</em> with the name of the family and use <code>paste()</code> to get the link.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="data-scraping-in-progress.html#cb81-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="st">&quot;Salmonidae&quot;</span></span>
<span id="cb81-2"><a href="data-scraping-in-progress.html#cb81-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb81-3"><a href="data-scraping-in-progress.html#cb81-3" aria-hidden="true" tabindex="-1"></a>url2<span class="ot">&lt;-</span><span class="fu">paste</span>(<span class="st">&quot;http://www.fishbase.org/Nomenclature/FamilySearchList.php?Family=&quot;</span>, y,<span class="at">sep=</span><span class="st">&quot;&quot;</span>) </span></code></pre></div>
<p>We then use <code>getURLContent()</code> to get the content of the link <em>url2</em> and save it in the variable <em>Content_Sal</em>.</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="data-scraping-in-progress.html#cb82-1" aria-hidden="true" tabindex="-1"></a>Content_Sal <span class="ot">&lt;-</span> <span class="fu">getURLContent</span>(url2, <span class="at">followlocation=</span><span class="cn">TRUE</span>) </span></code></pre></div>
<p>Next we create a dataframe using <code>data.frame()</code> and get a list of variables. We will extract the variables with the same number of rows and unique row names. The function <code>readHTMLTable()</code> (from earlier) helps to extract data from HTML tables in an HTML document.</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="data-scraping-in-progress.html#cb83-1" aria-hidden="true" tabindex="-1"></a>z <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">readHTMLTable</span>(Content_Sal))</span></code></pre></div>
<p>Then we can extract the species from the given family with <code>as.character()</code>. We use <code>z[,1]</code> to get the first column which is the column with the scientific names of species.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="data-scraping-in-progress.html#cb84-1" aria-hidden="true" tabindex="-1"></a>sp_per_family <span class="ot">&lt;-</span> <span class="fu">as.character</span>(z[,<span class="dv">1</span>])</span></code></pre></div>
<p>Now we can print the first element of the column with the scientific names.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="data-scraping-in-progress.html#cb85-1" aria-hidden="true" tabindex="-1"></a>sp_per_family[<span class="dv">1</span>]</span></code></pre></div>
<pre><code>## [1] &quot;Brachymystax lenok&quot;</code></pre>
<p>‘Brachymystax lenok’</p>
<p>Using <code>str_replace()</code> function we can substitute the empty space between the Genus and the Species with a <code>"-"</code>.</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="data-scraping-in-progress.html#cb87-1" aria-hidden="true" tabindex="-1"></a>sp_per_family <span class="ot">&lt;-</span> <span class="fu">str_replace</span>(sp_per_family, <span class="st">&quot; &quot;</span>, <span class="st">&quot;-&quot;</span>)</span></code></pre></div>
<p>Finally we can print the first element of <em>sp_per_family</em> again.</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="data-scraping-in-progress.html#cb88-1" aria-hidden="true" tabindex="-1"></a>sp_per_family[<span class="dv">1</span>]</span></code></pre></div>
<pre><code>## [1] &quot;Brachymystax-lenok&quot;</code></pre>
<p>‘Brachymystax-lenok’</p>
<hr />
<!-- ### 4.2 Getting the IUCN Status of a list of species -->
<!-- In this section, we are going to get the IUCN Status for a given List of species using a 'for loop'. We will extract the IUCN Status of all the species from the Netherlands. -->
<!-- First, we are going to upload the dataset containing the list of the species and some other data that is going to be useful for the next sections. We will do that by using the function `read_csv()`. This data came from https://www.nature.com/articles/sdata2017141 by cropping it to Western Europe. -->
<!-- ```{r} -->
<!-- suppressWarnings(suppressMessages( -->
<!-- dataset <- read_csv("../data/dataset2.csv"))) -->
<!-- ``` -->
<!-- As we only need data related to Netherlands, we will use the function `grep()` and pass _Netherlands_ as an argument. -->
<!-- ```{r} -->
<!-- subset <- dataset[grep("Netherlands", dataset$Country),] -->
<!-- ``` -->
<!-- Let's first briefly discuss how to construct a 'for loop', since it's been a while since you used it in previous chapters. To get the IUCN Status of a list of species we always change the value of _x_ (the species) and run the code, but if we have to do that for many species it will be very long and tedious. In this case 'for loops' come in handy. In a 'for loop' the variable _x_ runs over the vector (here each species) and returns the IUCN Status. Before getting the IUCN status let's just go over an easy example, such as printing the integers from 1 to 10 using a 'for loop'. In this case, we iterate over the vector 1:10.  -->
<!-- ```{r} -->
<!-- for(j in 1:10) { -->
<!-- print(j) # this prints the value of j for that given loop -->
<!-- } -->
<!-- ``` -->
<!--     [1] 1 -->
<!--     [1] 2 -->
<!--     [1] 3 -->
<!--     [1] 4 -->
<!--     [1] 5 -->
<!--     [1] 6 -->
<!--     [1] 7 -->
<!--     [1] 8 -->
<!--     [1] 9 -->
<!--     [1] 10 -->
<!-- Now we can make a 'for loop' in order to get the IUCN status of all the species in the above subset (Netherlands) of the initial dataset. We are going to iterate over the column of the dataset with the valid FishBase species names. The code lines inside the loop are exactly a copy-paste of what we had for the *Coregonus lavaretus*, but in this case, we have to look for other species. In the last line of the code below, we created a new column in the data frame _subset_ in order to save the IUCN Status. The 'i' in `subset$IUCN[i]` is used to save the IUCN status of the species we are iterating over in the 'for loop'. It will save the results of the species one by one.  -->
<!-- ```{r} -->
<!-- i <- 0 -->
<!-- for (x in subset$X6.Fishbase.Valid.Species.Name) { -->
<!-- i <- i + 1 -->
<!-- url3 <- paste("http://www.fishbase.de/summary/",x,".html",sep="")                 # we call the url -->
<!-- fish_species <- htmlParse(getURLContent(url3, followlocation=TRUE))              # get the content -->
<!-- fish_species_div <-getNodeSet(fish_species, "//div ")                            # get the node with the fish species (the nodeSet gets all the values inside the //div tag) -->
<!-- w_IUCN  <-which(sapply(lapply(fish_species_div,xmlValue),function(x)            # look for the IUCN content -->
<!--   {regexec(pattern="IUCN", x)[[1]][1]})>0) -->
<!-- if(length(w_IUCN)==0){                                                        # here we assign NA if the fileds are empty -->
<!--   IUCN_status="NA" -->
<!-- } else {                                                                     # else we read the information and iterate over the fields -->
<!--   d1_IUCN  <- xmlValue(fish_species_div[[w_IUCN[length(w_IUCN)]]]) -->
<!--   IUCN <- unlist(regmatches(d1_IUCN,gregexpr(pattern= "[[:alpha:]]+)",      -->
<!--   d1_IUCN))) -->
<!--   IUCN_status <- sub(pattern="[[:punct:]]",replacement="",IUCN[1] )  -->
<!-- }  -->
<!-- print(IUCN_status) -->
<!-- subset$IUCN[i] <- IUCN_status # make a new column in 'subset' containing the IUCN status -->
<!-- } -->
<!-- ``` -->
<!--     [1] "LC" -->
<!--     Warning message: -->
<!--     “Unknown or uninitialised column: `IUCN`.” -->
<!--     [1] "LC" -->
<!--     [1] "LC" -->
<!--     [1] "LC" -->
<!--     [1] "LC" -->
<!--     [1] "LC" -->
<!--     [1] "NT" -->
<!--     [1] NA -->
<!--     [1] NA -->
<!-- We can see which IUCN statuses are present in Netherlands by using the `unique()` function. -->
<!-- ```{r} -->
<!-- unique(subset$IUCN) -->
<!-- ``` -->
<!-- <style> -->
<!-- .list-inline {list-style: none; margin:0; padding: 0} -->
<!-- .list-inline>li {display: inline-block} -->
<!-- .list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex} -->
<!-- </style> -->
<!-- <ol class=list-inline><li>'LC'</li><li>'NT'</li><li>NA</li></ol> -->
<!-- --- -->
<!-- ### 4.3 Proportion of species in Netherlands -->
<!-- We will now plot the proportion of species in each category for the Netherlands. So let us calculate the number of species in each category (from above we just have 2 outputs, _LC_ & _NT_). In general in other countries, we also have other IUCN Status, for example, VU. In this section, we will focus only on the two listed statuses. Using the function `length()` we can obtain the number of species in each category. -->
<!-- ```{r} -->
<!-- number_lc <- length(which(subset$IUCN == "LC")) -->
<!-- number_nt <- length(which(subset$IUCN == "NT")) -->
<!-- # print the values for LC, using 'paste0()'' to help visualise the results. -->
<!-- paste0("LC:", " ", number_lc) -->
<!-- # print the values for NT -->
<!-- paste0("NT:", " ", number_nt) -->
<!-- ``` -->
<!-- 'LC: 6' -->
<!-- 'NT: 1' -->
<!-- We are ready to plot this as pie chart. -->
<!-- ```{r} -->
<!-- slices <- c(number_lc, number_nt) -->
<!-- lbls <- c("LC","NT") -->
<!-- pie(slices, labels = lbls,font.main = 1,  -->
<!-- main = "Proportion of species per IUCN Status in Netherlands", col=c("red", "yellow"))  -->
<!-- ``` -->
<!-- ![png](output_172_0.png) -->
<!-- ### 4.4 Cleaning the data with the IUCN Status -->
<!-- In this part of the tutorial, we have to clean the data that we will use for the correlations. We have provided the dataset already with the IUCN status since the code needs a lot of time to run, but the procedure is exactly the same as we did in the previous sections. So, let's load the dataset, it's called _datasetIUCN_. -->
<!-- ```{r} -->
<!-- suppressWarnings(suppressMessages( -->
<!-- dataset_IUCN <- read_csv("../data/datasetIUCN.csv") -->
<!-- )) -->
<!-- ``` -->
<!-- In the previous sections, we saw that for some species we did not have information on the IUCN status. In these cases, we set the IUCN status as NA. We can check for possible NA values by calling the `unique()` function.  -->
<!-- ```{r} -->
<!-- unique(dataset_IUCN$IUCN) -->
<!-- ``` -->
<!-- <style> -->
<!-- .list-inline {list-style: none; margin:0; padding: 0} -->
<!-- .list-inline>li {display: inline-block} -->
<!-- .list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex} -->
<!-- </style> -->
<!-- <ol class=list-inline><li>'LC'</li><li>'CR'</li><li>'lc'</li><li>'VU'</li><li>NA</li><li>'EX'</li><li>'NT'</li><li>'DD'</li><li>'EN'</li><li>'EW'</li></ol> -->
<!-- <div style="background-color:rgba(0, 200, 0, 0.5);border-radius: 7px; padding:10px"> -->
<!--     <b>Checkpoint</b><br/> -->
<!--      Now your task is to remove the row with the IUCN status as NA. You can use the function `subset()` to get the subset of the dataset with information about the IUCN status. -->
<!-- </div> -->
<!-- ```{r} -->
<!-- # your code -->
<!-- ``` -->
<!-- ```{r} -->
<!-- ### Solution -->
<!-- # subset the data without NAs (!=NA; not equal to NA), so this effectively removes the NAs -->
<!-- dataset_IUCN_NA <- subset(dataset_IUCN, dataset_IUCN$IUCN != "NA") -->
<!-- # check it worked -->
<!-- unique(dataset_IUCN_NA$IUCN) -->
<!-- ``` -->
<!-- <style> -->
<!-- .list-inline {list-style: none; margin:0; padding: 0} -->
<!-- .list-inline>li {display: inline-block} -->
<!-- .list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex} -->
<!-- </style> -->
<!-- <ol class=list-inline><li>'LC'</li><li>'CR'</li><li>'lc'</li><li>'VU'</li><li>'EX'</li><li>'NT'</li><li>'DD'</li><li>'EN'</li><li>'EW'</li></ol> -->
<!-- Next, we will load the shapefile of glacial basins using the package <b>rgdal</b> and the function `readOGR()`. We fetch the data from different fish basins across Europe in the _basin_shapefile_ from the data stored in the basins folder.  -->
<!-- ```{r} -->
<!-- basin_shapefile <- readOGR("../data/basins") -->
<!-- ``` -->
<!--     OGR data source with driver: ESRI Shapefile  -->
<!--     Source: "/work/04_data_scraping/data/basins", layer: "basins_glaciation" -->
<!--     with 250 features -->
<!--     It has 11 fields -->
<!-- In order to plot the basins on the map we will use `fortify()` function on the _basin_shapefile_. This function helps to convert a lines and points object to a data frame for ggplot. We will store this dataframe as _fort_basin_. -->
<!-- ```{r} -->
<!-- fort_basin <- fortify(basin_shapefile) -->
<!-- head(fort_basin) -->
<!-- ``` -->
<!--     Regions defined for each Polygons -->
<!-- <table> -->
<!-- <caption>A data.frame: 6 × 7</caption> -->
<!-- <thead> -->
<!--    <tr><th></th><th scope=col>long</th><th scope=col>lat</th><th scope=col>order</th><th scope=col>hole</th><th scope=col>piece</th><th scope=col>id</th><th scope=col>group</th></tr> -->
<!--    <tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;fct&gt;</th></tr> -->
<!-- </thead> -->
<!-- <tbody> -->
<!--    <tr><th scope=row>1</th><td>-5.658333</td><td>36.05417</td><td>1</td><td>FALSE</td><td>1</td><td>0</td><td>0.1</td></tr> -->
<!--    <tr><th scope=row>2</th><td>-5.668877</td><td>36.05473</td><td>2</td><td>FALSE</td><td>1</td><td>0</td><td>0.1</td></tr> -->
<!--    <tr><th scope=row>3</th><td>-5.672790</td><td>36.05777</td><td>3</td><td>FALSE</td><td>1</td><td>0</td><td>0.1</td></tr> -->
<!--    <tr><th scope=row>4</th><td>-5.677210</td><td>36.05890</td><td>4</td><td>FALSE</td><td>1</td><td>0</td><td>0.1</td></tr> -->
<!--    <tr><th scope=row>5</th><td>-5.681123</td><td>36.06193</td><td>5</td><td>FALSE</td><td>1</td><td>0</td><td>0.1</td></tr> -->
<!--    <tr><th scope=row>6</th><td>-5.685544</td><td>36.06307</td><td>6</td><td>FALSE</td><td>1</td><td>0</td><td>0.1</td></tr> -->
<!-- </tbody> -->
<!-- </table> -->
<!-- We can visualise our _basin_shapefile_ using `ggplot()`. -->
<!-- ```{r} -->
<!-- ggplot() + geom_polygon(data = fort_basin, aes(x = long, y = lat, group = group), colour = "black", fill = NA) -->
<!-- ``` -->
<!-- ![png](output_186_0.png) -->
<!-- ### 4.5 Maps of species richness and Red List species proportions -->
<!-- We now want to map the species richness and Red List species proportions. -->
<!-- Let us first calculate the species richness and proportion of Red List species per basin. Species richness is the number of species pro basin and the proportion of red list species is the ratio between the number of species in the red list and the number of species pro basin. We will iterate over the vector with the basin names and we will use the function `nrow()` to find the number of occurrences.   -->
<!-- ```{r} -->
<!-- for (x in as.character(basin_shapefile$BasinName)) { -->
<!--   # we now restrict to dataset to the basin x -->
<!--   dataset_basins <- dataset_IUCN[dataset_IUCN$X1.Basin.Name==x,] -->
<!--   # number of species in the given country x -->
<!--   n1 <- nrow(dataset_basins) -->
<!--   # we now restrict to dataset to the country x and Red List -->
<!--   dataset_c_IUCN <- dataset_basins[grep("VU|EN|EX|EW|CR", dataset_basins$IUCN),]  -->
<!--   # number of species in the given country x with given IUCN Status -->
<!--   n2 <- nrow(dataset_c_IUCN) -->
<!--   # compute the proportion  -->
<!--   basin_shapefile$proportion[basin_shapefile$BasinName==x] <- n2/n1 -->
<!--   basin_shapefile$richness[basin_shapefile$BasinName==x] <- n1   -->
<!-- } -->
<!-- ``` -->
<!-- We can see the newly computed data for the columns _'proportion'_ and _'richness'_ with respect to each basin in the _basin_shapefile_.  -->
<!-- ```{r} -->
<!-- head(basin_shapefile@data) -->
<!-- ``` -->
<!-- <table> -->
<!-- <caption>A data.frame: 6 × 13</caption> -->
<!-- <thead> -->
<!--    <tr><th></th><th scope=col>BasinName</th><th scope=col>Country</th><th scope=col>Ecoregion</th><th scope=col>Endorheic</th><th scope=col>Out_Longit</th><th scope=col>Out_Latit</th><th scope=col>Med_Longit</th><th scope=col>Med_Latit</th><th scope=col>Surf_area</th><th scope=col>ice_dist</th><th scope=col>temp</th><th scope=col>proportion</th><th scope=col>richness</th></tr> -->
<!--    <tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr> -->
<!-- </thead> -->
<!-- <tbody> -->
<!--    <tr><th scope=row>0</th><td>Valle           </td><td>Spain  </td><td>Palearctic</td><td>NA</td><td> -5.721676</td><td>36.06629</td><td> -5.7671465</td><td>36.11803</td><td>  146.6600</td><td>1592409.4</td><td>18.031604</td><td>0.25000000</td><td> 8</td></tr> -->
<!--    <tr><th scope=row>1</th><td>Laxa.Leirarsveit</td><td>Iceland</td><td>Palearctic</td><td>NA</td><td>-21.874556</td><td>64.39327</td><td>-21.6432853</td><td>64.44753</td><td>  187.1266</td><td> 368687.7</td><td> 2.507056</td><td>       NaN</td><td> 0</td></tr> -->
<!--    <tr><th scope=row>2</th><td>Andakilsa       </td><td>Iceland</td><td>Palearctic</td><td>NA</td><td>-21.781420</td><td>64.54236</td><td>-21.4828095</td><td>64.49633</td><td>  219.6690</td><td> 387360.4</td><td> 3.113605</td><td>       NaN</td><td> 0</td></tr> -->
<!--    <tr><th scope=row>3</th><td>Aa              </td><td>France </td><td>Palearctic</td><td>NA</td><td>  2.098209</td><td>51.01710</td><td>  2.0492197</td><td>50.78136</td><td> 1200.3646</td><td> 261541.3</td><td>10.529269</td><td>0.06666667</td><td>30</td></tr> -->
<!--    <tr><th scope=row>4</th><td>Adour           </td><td>France </td><td>Palearctic</td><td>NA</td><td> -1.498072</td><td>43.53500</td><td> -0.5065982</td><td>43.42947</td><td>16911.1610</td><td> 875198.0</td><td>12.460502</td><td>0.08888889</td><td>45</td></tr> -->
<!--    <tr><th scope=row>5</th><td>Agly            </td><td>France </td><td>Palearctic</td><td>NA</td><td>  3.046515</td><td>42.81225</td><td>  2.6066918</td><td>42.81292</td><td> 1125.2007</td><td>1060457.1</td><td>13.120775</td><td>0.09090909</td><td>22</td></tr> -->
<!-- </tbody> -->
<!-- </table> -->
<!-- Next we get the map of Europe. We will read the data in the _continent_shapefile_ and then will extract the continent 'Europe' map. If you call the variable _europe_, you will see that the dataframe is empty. This is because it extracts only the map data which we can simply plot by passing the europe as an argument in `plot()` function. We will do it in the upcoming code cells. -->
<!-- ```{r} -->
<!-- continents <- readOGR('../data/continent_shapefile') -->
<!-- europe <- continents[continents$CONTINENT=='Europe',] -->
<!-- ``` -->
<!--     Warning message in readOGR("../data/continent_shapefile"): -->
<!--     “First layer europe_map read; multiple layers present in -->
<!--     /work/04_data_scraping/data/continent_shapefile, check layers with ogrListLayers()” -->
<!--     OGR data source with driver: ESRI Shapefile  -->
<!--     Source: "/work/04_data_scraping/data/continent_shapefile", layer: "europe_map" -->
<!--     with 53 features -->
<!--     It has 94 fields -->
<!-- **So now let us plot the proportions of Red List species.**  -->
<!-- First, we will create a new column _'proportion_colour'_ and in this column, we will store the colours. Then we will break the proportions into 10 different parts by grouping the values in the proportion column into 10 using the `cut()` function. Then we get rid of the index vector using `as.numeric()` and get all the values as numeric values. We used the `rev()` function to reverse the colours, red colour indicates the species that are getting distinct and have very less proportion pro basin and yellow indicates the species with comparatively more proportion in the basin. Finally, we store these colours to the column proportion_colour. The colour indicates the proportion of Red List species occurring in the corresponding basin. We do the same for the species richness. -->
<!-- ```{r} -->
<!-- basin_shapefile$proportion_colour <- rev(heat.colors(11))[as.numeric(cut(basin_shapefile$proportion, breaks = 10))] -->
<!-- ``` -->
<!-- Now we create a new column in the _fort_basin_ dataframe and map the values of _'proportion_colour'_ into the new color column. We are doing this to have the colour (species proportion divided into 10 parts) and lat-long values in one datframe which helps to plot the graph using `ggplot()`.  -->
<!-- ```{r} -->
<!-- fort_basin$color <- fort_basin$id    # create a new column color -->
<!-- for (i in as.numeric(unique(fort_basin$id))) # map the values into color column by id -->
<!-- { -->
<!--    fort_basin$color[fort_basin$id == i] <- basin_shapefile@data$proportion_colour[i+1] -->
<!-- } -->
<!-- ``` -->
<!-- Remember above we extracted the continent _'europe'_ from the _continent_shapefile_, here we will use `fortiy()` on the europe dataset to plot it using ggplot also. -->
<!-- ```{r} -->
<!-- fort_europe <- fortify(europe) -->
<!-- ``` -->
<!--     Regions defined for each Polygons -->
<!-- We will plot the _fort_europe_ and _fort_basin_ data on the map. -->
<!-- ```{r} -->
<!-- ggplot(fort_basin, aes(x = long, y = lat, group = group)) + -->
<!--   geom_polygon(data = fort_europe, aes(x = long, y = lat, group = group), colour = 'white') + -->
<!--   geom_polygon(fill = fort_basin$color, colour = "black")+ -->
<!--   xlim(-25, 28) -->
<!-- ``` -->
<!-- ![png](output_201_0.png) -->
<!-- From the graph, we see that the proportion of Red List species is highest in South-Western Europe. The aim of the Red List is to inform decision-makers about potentially endangered species, i.e. species whose population size has been rapidly declining during the last decades or the species that only occur in small numbers at present. The proportion of species on the Red List of each region, therefore, gives an indication of the risk of species going extinct in a region and represents an important tool for conservation strategies. -->
<!-- **We will repeat the above steps all together for plotting the species richness on map.** -->
<!-- ```{r} -->
<!-- # break the richness  of the species into 10 parts and then we assign colours to each part  -->
<!-- basin_shapefile$richness_colour <- rev(heat.colors(11))[as.numeric(cut(basin_shapefile$richness, breaks = 10))] -->
<!-- fort_basin$rich_color <- fort_basin$id    # create a new column rich_color -->
<!-- # mapping the values from basin_shapefile to fort_basin -->
<!-- for (i in as.numeric(unique(fort_basin$id)))  -->
<!-- { -->
<!--    fort_basin$rich_color[fort_basin$id == i] <- basin_shapefile@data$richness_colour[i+1] -->
<!-- } -->
<!-- # plot -->
<!-- ggplot(fort_basin, aes(x = long, y = lat, group = group)) + -->
<!--   geom_polygon(data = fort_europe, aes(x = long, y = lat, group = group), colour = 'white') + -->
<!--   geom_polygon(fill = fort_basin$rich_color, colour = "black")+ -->
<!--   xlim(-25, 28) -->
<!-- ``` -->
<!-- ![png](output_204_0.png) -->
<!-- ### 4.6 Investigate the relationship of basin size and species richness -->
<!-- In the previous section, you observed the spatial patterns of fish diversity across Europe. In this section, we will try to explain these patterns. To achieve this, we will correlate the fish species richness of each basin to the surface area of the corresponding area to see how the species richness varies with respect to the surface area of the basin. We begin with plotting a simple scatterplot. We will log transform the data we have on surface area as it helps to make data conform to normality and also helps to deal with the outliers and skeweness in the data. Then we will plot this data against species richness. Since the data-deficient basins show zero observations in the dataframe, we will remove those first.  -->
<!-- ```{r} -->
<!-- basin_shapefile <- basin_shapefile[basin_shapefile$richness!=0,] -->
<!-- ``` -->
<!-- Now we will create a new dataframe with the _surface area_ and _richness_. We'll the columns as _'Basin_area'_ and _'Species_richness'_ respectively. -->
<!-- ```{r} -->
<!-- bs_sr <- tibble(basin_shapefile@data$Surf_area, basin_shapefile@data$richness ) -->
<!-- names(bs_sr)[1]<- 'Basin_area' -->
<!-- names(bs_sr)[2]<- 'Species_richness' -->
<!-- ``` -->
<!-- We make a simple scratterplot with a regression line to visualise the relationship. -->
<!-- ```{r} -->
<!-- ggplot(bs_sr, aes(x = log(Basin_area), y = Species_richness)) + -->
<!-- geom_point() + -->
<!-- geom_smooth(method='lm', color="red", size=0.5, se=FALSE)+ -->
<!-- xlab("Basin Area") + -->
<!-- ylab("Species Richness") + -->
<!-- theme_classic() -->
<!-- ``` -->
<!--     `geom_smooth()` using formula 'y ~ x' -->
<!-- ![png](output_211_1.png) -->
<!-- The plot shows a positive correlation between basin area and fish richness, meaning that we expect to see a higher richness in larger basins. This pattern is commonly observed in ecology and one explanation for this is that larger areas provide different habitat types (niches), which allows more species to co-exist. -->
<!-- As a next step, we will create a simple model of this relationship. This allows us to make predictions on the richness of fish species in other basins based on the basin area. -->
<!-- ```{r} -->
<!-- #create a linear model -->
<!-- richness_model <- lm(richness~log(Surf_area), data=basin_shapefile@data) -->
<!-- ``` -->
<!-- We now want to calculate the confidence intervals of the model to have a better idea of the uncertainty of the model. We will then coerce the basin surface, the model fit and the confidence interval into a new data frame called *model_df*. -->
<!-- ```{r} -->
<!-- #calculate the confidence intervals -->
<!-- model_df <- as.data.frame(cbind(log(basin_shapefile$Surf_area), predict(richness_model, interval='confidence'))) -->
<!-- names(model_df)[1] <- 'log_area' -->
<!-- head(model_df) -->
<!-- ``` -->
<!-- <table> -->
<!-- <caption>A data.frame: 6 × 4</caption> -->
<!-- <thead> -->
<!--    <tr><th></th><th scope=col>log_area</th><th scope=col>fit</th><th scope=col>lwr</th><th scope=col>upr</th></tr> -->
<!--    <tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr> -->
<!-- </thead> -->
<!-- <tbody> -->
<!--    <tr><th scope=row>0</th><td>4.988117</td><td> 7.215144</td><td> 4.416531</td><td>10.01376</td></tr> -->
<!--    <tr><th scope=row>3</th><td>7.090381</td><td>20.001125</td><td>18.488035</td><td>21.51421</td></tr> -->
<!--    <tr><th scope=row>4</th><td>9.735729</td><td>36.090151</td><td>34.001427</td><td>38.17887</td></tr> -->
<!--    <tr><th scope=row>5</th><td>7.025717</td><td>19.607838</td><td>18.069980</td><td>21.14570</td></tr> -->
<!--    <tr><th scope=row>6</th><td>7.492151</td><td>22.444692</td><td>21.046504</td><td>23.84288</td></tr> -->
<!--    <tr><th scope=row>7</th><td>6.602807</td><td>17.035701</td><td>15.301404</td><td>18.77000</td></tr> -->
<!-- </tbody> -->
<!-- </table> -->
<!-- The final step is  to plot the model fit and prediction intervals over the data. To get nice lines in the plot, the *model_df* dataframe needs to be ordered by the basin area first. -->
<!-- ```{r} -->
<!-- ggplot(bs_sr, aes(x = log(Basin_area), y = Species_richness)) + -->
<!-- geom_point() + -->
<!-- geom_line(aes(x = model_df$log_area, y= model_df$fit ), color = "red")+ -->
<!-- geom_line(aes(x = model_df$log_area, y= model_df$lwr ), color = "red", linetype = "dotted")+ -->
<!-- geom_line(aes(x = model_df$log_area, y= model_df$upr ), color = "red", linetype = "dotted")+ -->
<!-- xlab("Basin Area") + -->
<!-- ylab("Species Richness") + -->
<!-- theme_classic() -->
<!-- ``` -->
<!-- ![png](output_217_0.png) -->
<!-- <div style="background-color:rgba(0, 200, 0, 0.5);border-radius: 7px; padding:10px"> -->
<!--     <b>Checkpoint</b><br/> -->
<!--      You have now seen how you can calculate and plot the confidence interval of your data. Based on your model you can also create a so called <b>prediction interval</b> which gives an estimate of the range in which the model will most likely predict the y-values (for a given x-value). In our case the prediction interval would indicate in which range the model would expect the fish richness to be for a given basin surface area. Do you think that these prediction intervals will be broader or narrower than the confidence interval? Try to write the code for calculating and plotting the prediction intervals by yourself. -->
<!-- </div> -->
<!-- ```{r} -->
<!-- # your code -->
<!-- ``` -->
<!-- ```{r} -->
<!-- ### Solution -->
<!-- #prediction intervals -->
<!-- # make a dataframe of area and richness model predictions -->
<!-- model_df_prediction <- as.data.frame(cbind(log(basin_shapefile$Surf_area), predict(richness_model, interval='prediction'))) -->
<!-- names(model_df_prediction)[1] <- 'log_area'  -->
<!-- # order the basins by size -->
<!-- model_df_prediction <- model_df_prediction[order(model_df_prediction$log_area),] -->
<!-- # plot the model -->
<!-- plot(log(basin_shapefile$Surf_area), basin_shapefile$richness, pch=16, cex=1, col=rgb(0,0,0,0.6), xlab='Basin area', ylab='Basin species richness') -->
<!-- lines(model_df_prediction$log_area, model_df_prediction$fit, col='skyblue3', lwd=2) -->
<!-- lines(model_df_prediction$log_area, model_df_prediction$lwr, col='skyblue2', lwd=2, lty=3) -->
<!-- lines(model_df_prediction$log_area, model_df_prediction$upr, col='skyblue2', lwd=2, lty=3) -->
<!-- ``` -->
<!--     Warning message in predict.lm(richness_model, interval = "prediction"): -->
<!--     “predictions on current data refer to _future_ responses -->
<!--     ” -->
<!-- ![png](output_220_1.png) -->
<hr />
</div>
</div>
<div id="references" class="section level2" number="5.6">
<h2><span class="header-section-number">5.6</span> 5. References</h2>
<ul>
<li>Automated Data Collection with R, S. Munzert, C. Rubba, P. Meißner and D. Nyhuis</li>
<li>XML and Web Technologies for Data Sciences with R, D. Nolan, D. Temple Lang</li>
<li><a href="http://www.columbia.edu/~cjd11/charles_dimaggio/DIRE/styled-4/styled-6/code-13/" class="uri">http://www.columbia.edu/~cjd11/charles_dimaggio/DIRE/styled-4/styled-6/code-13/</a></li>
<li><a href="https://ourcodingclub.github.io/tutorials/webscraping/" class="uri">https://ourcodingclub.github.io/tutorials/webscraping/</a></li>
<li><a href="https://www.earthdatascience.org/courses/earth-analytics/get-data-using-apis/use-twitter-api-r/" class="uri">https://www.earthdatascience.org/courses/earth-analytics/get-data-using-apis/use-twitter-api-r/</a></li>
</ul>
<hr />
</div>
<div id="exercise" class="section level2" number="5.7">
<h2><span class="header-section-number">5.7</span> Exercise</h2>
<p>For this week’s exercise open up the Rstudio environment. Remember to save all your changes to this notebook using git status, git add <filename>, git commit -m “your comment,” git push.</p>
<p>Exercise 04 is about getting data from the web and extracting usefull insights from it.</p>
<p>Get in touch with your teaching assistant if you have any further questions.</p>
<hr />

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data-variety.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="catch-up.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["esds_book.pdf", "esds_book.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
